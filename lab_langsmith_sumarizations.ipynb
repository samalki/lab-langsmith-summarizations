{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "52bb9c6d-7a1c-480a-93c9-acf847773163",
      "metadata": {
        "id": "52bb9c6d-7a1c-480a-93c9-acf847773163"
      },
      "source": [
        "# Lab | Summarization evaluation using LangSmith\n",
        "Let's revisit your capstone project 2? Well, sort of. Pick diffierent sets of data and re-run this notebook. Maybe parts of the dataset you used in your last project week. The point is for you to understand all steps involve and the many different ways one can and should evaluate LLM applications using LangSmith.\n",
        "\n",
        "What did you learn? - Let's discuss that in class"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00830bb4-eb0f-4439-9ceb-c5956d28a8a9",
      "metadata": {
        "id": "00830bb4-eb0f-4439-9ceb-c5956d28a8a9"
      },
      "source": [
        "## LangSmith - LangChain evaluation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv datasets langsmith langchain langchain_openai rapidfuzz\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2v_QRhSwQchw",
        "outputId": "bc2768f2-4402-4d3a-e3a2-88e0d46f7105"
      },
      "id": "2v_QRhSwQchw",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: langsmith in /usr/local/lib/python3.11/dist-packages (0.3.31)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.23)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.14-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting rapidfuzz\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith) (3.10.16)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langsmith) (2.11.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith) (0.23.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.52)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Collecting langchain-core<1.0.0,>=0.3.51 (from langchain)\n",
            "  Downloading langchain_core-0.3.55-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.75.0)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (1.0.8)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.14.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langsmith) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langsmith) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langsmith) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading langchain_openai-0.3.14-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.55-py3-none-any.whl (434 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.1/434.1 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, tiktoken, langchain-core, langchain_openai\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.52\n",
            "    Uninstalling langchain-core-0.3.52:\n",
            "      Successfully uninstalled langchain-core-0.3.52\n",
            "Successfully installed langchain-core-0.3.55 langchain_openai-0.3.14 rapidfuzz-3.13.0 tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oy94Eg8BMub0",
        "outputId": "37c2f66a-2f1d-43d4-909b-c9743db7f63f"
      },
      "id": "Oy94Eg8BMub0",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "6db4887a-a214-49bc-9bb6-0ae59c1092ec",
      "metadata": {
        "id": "6db4887a-a214-49bc-9bb6-0ae59c1092ec",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv, find_dotenv\n",
        "import os\n",
        "_ = load_dotenv(find_dotenv())\n",
        "\n",
        "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')\n",
        "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
        "HUGGINGFACEHUB_API_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "5f4adff9-1169-4173-a72b-c983dcb6160d",
      "metadata": {
        "id": "5f4adff9-1169-4173-a72b-c983dcb6160d",
        "tags": []
      },
      "outputs": [],
      "source": [
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"]=\"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"]=\"langsmith_amazon-reviews\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "0189af0e-8145-407b-a32d-2f21ac0ca5ff",
      "metadata": {
        "id": "0189af0e-8145-407b-a32d-2f21ac0ca5ff",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#Importing Client from Langsmith\n",
        "from langsmith import Client\n",
        "client = Client(api_key=LANGCHAIN_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e7c4be2-fdae-42cf-b1b2-9aef89081ad2",
      "metadata": {
        "id": "4e7c4be2-fdae-42cf-b1b2-9aef89081ad2"
      },
      "source": [
        "### Create Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iw4iLTmdM5ib",
        "outputId": "d868a0f0-a715-4569-cef0-3de712a3c5f8"
      },
      "id": "Iw4iLTmdM5ib",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Electronics_5.json.gz\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQ60VpvIRNSD",
        "outputId": "fbe04184-ea57-4c3f-c562-3a0f686856ec"
      },
      "id": "yQ60VpvIRNSD",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-23 06:10:24--  http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Electronics_5.json.gz\n",
            "Resolving snap.stanford.edu (snap.stanford.edu)... 171.64.75.80\n",
            "Connecting to snap.stanford.edu (snap.stanford.edu)|171.64.75.80|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 495854086 (473M) [application/x-gzip]\n",
            "Saving to: ‘reviews_Electronics_5.json.gz’\n",
            "\n",
            "reviews_Electronics 100%[===================>] 472.88M  9.27MB/s    in 91s     \n",
            "\n",
            "2025-04-23 06:11:56 (5.21 MB/s) - ‘reviews_Electronics_5.json.gz’ saved [495854086/495854086]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "dbc219ae-1760-4f3d-92e6-aaeb6fb7ee9f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555,
          "referenced_widgets": [
            "e6899eb4c04d40b79c8e4d0ac08082d0",
            "97871f0d4c6044e982804ee2c5db7101",
            "7dd73b93420546cca6726758f78c5bde",
            "e3b826ca45234699859d8d6c1298f670",
            "8a635343dde14ce8bb10c7dd7d01dc55",
            "7b59393451c641c9807007a096fa956e",
            "016d45bf3430435faa794b2fc0069ebe",
            "a4dcf77794db4d60b1850a63d3965ca9",
            "06cd07a39079433aa0250e3feda51524",
            "4ca5bdd5ef8c4ae1bc54a1d171c6c273",
            "cb8c9f1a17db40d898ae910466ba886c",
            "67b58846594d40a9b6d9e854cc5ad702",
            "cbc74bd17d29446884ea5894e3842676",
            "503c67016707445dbb0650053c722d92",
            "10658ec45c3049b98bfbb35c216384ae",
            "55250c78778b431f84d7deb0661b5219",
            "04a98f1be8be45b891090569ebf79f59",
            "c5ab879808ff431d90ca1a0e28728daa",
            "cf6f1f4ce0d44a5ba57b511f95953161",
            "a46b980a03cb4a5eb8af0de9e32c21a2",
            "99731e13188049b6a16820370ff8bfe1",
            "6f8cf7c64a3349a298f19529736dff85"
          ]
        },
        "id": "dbc219ae-1760-4f3d-92e6-aaeb6fb7ee9f",
        "outputId": "b4322fee-107c-4c40-ed07-10c98b6e6641",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6899eb4c04d40b79c8e4d0ac08082d0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67b58846594d40a9b6d9e854cc5ad702"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'reviewerID': 'AO94DHGC771SJ',\n",
              " 'asin': '0528881469',\n",
              " 'reviewerName': 'amazdnu',\n",
              " 'helpful': [0, 0],\n",
              " 'reviewText': 'We got this GPS for my husband who is an (OTR) over the road trucker.  Very Impressed with the shipping time, it arrived a few days earlier than expected...  within a week of use however it started freezing up... could of just been a glitch in that unit.  Worked great when it worked!  Will work great for the normal person as well but does have the \"trucker\" option. (the big truck routes - tells you when a scale is coming up ect...)  Love the bigger screen, the ease of use, the ease of putting addresses into memory.  Nothing really bad to say about the unit with the exception of it freezing which is probably one in a million and that\\'s just my luck.  I contacted the seller and within minutes of my email I received a email back with instructions for an exchange! VERY impressed all the way around!',\n",
              " 'overall': 5.0,\n",
              " 'summary': 'Gotta have GPS!',\n",
              " 'unixReviewTime': 1370131200,\n",
              " 'reviewTime': '06 2, 2013',\n",
              " 'review': 'Summarize this customer review:\\nWe got this GPS for my husband who is an (OTR) over the road trucker.  Very Impressed with the shipping time, it arrived a few days earlier than expected...  within a week of use however it started freezing up... could of just been a glitch in that unit.  Worked great when it worked!  Will work great for the normal person as well but does have the \"trucker\" option. (the big truck routes - tells you when a scale is coming up ect...)  Love the bigger screen, the ease of use, the ease of putting addresses into memory.  Nothing really bad to say about the unit with the exception of it freezing which is probably one in a million and that\\'s just my luck.  I contacted the seller and within minutes of my email I received a email back with instructions for an exchange! VERY impressed all the way around!'}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"json\", data_files=\"reviews_Electronics_5.json.gz\")\n",
        "small_reviews = dataset['train'].select(range(20))\n",
        "def add_prefix(example):\n",
        "    return {\n",
        "        \"review\": f\"Summarize this customer review:\\n{example['reviewText']}\",\n",
        "        \"summary\": example.get(\"summary\", \"\")\n",
        "    }\n",
        "\n",
        "sample_reviews = small_reviews.map(add_prefix)\n",
        "sample_reviews[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv, find_dotenv\n",
        "import os\n",
        "\n",
        "_ = load_dotenv(find_dotenv())\n",
        "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
        "\n",
        "print(\"API Key:\", LANGCHAIN_API_KEY)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Tsj1qyITVXy",
        "outputId": "07b82347-6511-4ce8-95ee-46d3fb1c6cd9"
      },
      "id": "2Tsj1qyITVXy",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API Key: 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\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langsmith import Client\n",
        "import datetime\n",
        "\n",
        "client = Client(api_key=LANGCHAIN_API_KEY)\n",
        "\n",
        "input_keys = ['review']\n",
        "output_keys = ['summary']\n",
        "dataset_name = f\"amazon_reviews_dataset_{datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
        "\n",
        "dataset = client.upload_dataframe(\n",
        "    df=sample_reviews,\n",
        "    input_keys=input_keys,\n",
        "    output_keys=output_keys,\n",
        "    name=dataset_name,\n",
        "    description=\"Customer review summarization - Amazon Electronics\",\n",
        "    data_type=\"kv\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c9d3f0c835874b2c9f6a17422e6d0f78",
            "6688d21811a040ed814adc833e81cbd3",
            "fa3c4b03b7c14793b8b544a6e14a9f89",
            "e7914bcf73f24768ab2a739c6d1b70cb",
            "72145e841ea1485ba1bb3ee4e4e8aa6e",
            "a7b2af2fccc04ebd842b264bea776282",
            "5f2c5b6112004f1784ff7fb0e252f249",
            "c034804727d247449b518d17675f45b7",
            "e7a71a3380d14c4e8e376017ac42956c",
            "98cd6bfd3e6c40cb9614f441a24eb1b2",
            "6d5f98e6f0b5482fb261ddea40b0af56"
          ]
        },
        "id": "9vhJ8OXjR_Ty",
        "outputId": "3c25afa1-7044-46db-b1a1-2614d0658c58"
      },
      "id": "9vhJ8OXjR_Ty",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9d3f0c835874b2c9f6a17422e6d0f78"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade langchain langchain-community langchain-openai\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qUumct9TnjP",
        "outputId": "bab24d3b-0259-4b49-a097-633d304fab1d"
      },
      "id": "3qUumct9TnjP",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.23)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.24-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.22-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (0.3.14)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.55 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.55)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.31)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.75.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.19.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.55->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain-0.3.24-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.22-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain, langchain-community\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.23\n",
            "    Uninstalling langchain-0.3.23:\n",
            "      Successfully uninstalled langchain-0.3.23\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.24 langchain-community-0.3.22 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.9.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-huggingface\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7CCd0M-T0yn",
        "outputId": "7b88b9dd-d596-4c82-9681-f4647b4b0385"
      },
      "id": "_7CCd0M-T0yn",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-huggingface\n",
            "  Downloading langchain_huggingface-0.1.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.30.2)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.3.55)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (3.4.1)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.21.1)\n",
            "Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2024.12.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.13.2)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.3.31)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.33)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (2.11.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.14.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (11.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain-huggingface) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain-huggingface) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain-huggingface) (0.5.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2025.1.31)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.6.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.3.1)\n",
            "Downloading langchain_huggingface-0.1.2-py3-none-any.whl (21 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m142.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m110.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, langchain-huggingface\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed langchain-huggingface-0.1.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "import os\n"
      ],
      "metadata": {
        "id": "JH2fY67cU-5W"
      },
      "id": "JH2fY67cU-5W",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\n"
      ],
      "metadata": {
        "id": "OvwVIi9QUjGW"
      },
      "id": "OvwVIi9QUjGW",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "from langchain_openai import OpenAI\n",
        "\n",
        "summarizer_base = HuggingFaceHub(\n",
        "    repo_id=\"t5-base\",\n",
        "    model_kwargs={\"temperature\": 0, \"max_length\": 180},\n",
        "    huggingfacehub_api_token=HUGGINGFACEHUB_API_TOKEN\n",
        ")\n",
        "\n",
        "summarizer_finetuned = HuggingFaceHub(\n",
        "    repo_id=\"flax-community/t5-base-cnn-dm\",\n",
        "    model_kwargs={\"temperature\": 0, \"max_length\": 180},\n",
        "    huggingfacehub_api_token=HUGGINGFACEHUB_API_TOKEN\n",
        ")\n",
        "\n",
        "openai_model = OpenAI(temperature=0.0, openai_api_key=OPENAI_API_KEY)\n"
      ],
      "metadata": {
        "id": "wIsN7JtnTb8o"
      },
      "id": "wIsN7JtnTb8o",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.smith import run_on_dataset, RunEvalConfig\n",
        "\n",
        "evaluation_config = RunEvalConfig(\n",
        "    evaluators=[\n",
        "        \"embedding_distance\",\n",
        "        # \"string_distance\"\n",
        "    ],\n",
        ")\n",
        "\n",
        "# تقييم T5-base\n",
        "project_name = f\"T5-BASE {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
        "run_on_dataset(\n",
        "    client=client,\n",
        "    project_name=project_name,\n",
        "    dataset_name=dataset_name,\n",
        "    llm_or_chain_factory=summarizer_base,\n",
        "    evaluation=evaluation_config,\n",
        ")\n",
        "\n",
        "# تقييم T5-finetuned\n",
        "project_name = f\"T5-FineTuned {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
        "run_on_dataset(\n",
        "    client=client,\n",
        "    project_name=project_name,\n",
        "    dataset_name=dataset_name,\n",
        "    llm_or_chain_factory=summarizer_finetuned,\n",
        "    evaluation=evaluation_config,\n",
        ")\n",
        "\n",
        "# تقييم OpenAI\n",
        "project_name = f\"OpenAI {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
        "run_on_dataset(\n",
        "    client=client,\n",
        "    project_name=project_name,\n",
        "    dataset_name=dataset_name,\n",
        "    llm_or_chain_factory=openai_model,\n",
        "    evaluation=evaluation_config,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njLdK4a9VfK0",
        "outputId": "fe776383-38eb-4a9c-96f8-3dd1a27aa3af"
      },
      "id": "njLdK4a9VfK0",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "View the evaluation results for project 'T5-BASE 2025-04-23 06:29:06' at:\n",
            "https://smith.langchain.com/o/fd08d518-ad5a-4f9a-8f8c-5dbc431268de/datasets/e33395c3-e366-4dcb-80fd-b3afe886321c/compare?selectedSessions=e778cdce-c842-4399-8c61-86cc0e5a6f28\n",
            "\n",
            "View all tests for Dataset amazon_reviews_dataset_2025-04-23 06:19:43 at:\n",
            "https://smith.langchain.com/o/fd08d518-ad5a-4f9a-8f8c-5dbc431268de/datasets/e33395c3-e366-4dcb-80fd-b3afe886321c\n",
            "[>                                                 ] 0/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example 48e11ae3-3535-4246-8b25-61e3516e8ccc with inputs {'review': 'Summarize this customer review:\\nThis adapter easily connects my Nook HD 7&#34; to my HDTV through the HDMI cable.  This is good for traveling because it makes any hotel TV a potential smart TV so long as there is an accessible HDMI port.  It is also good for sharing photos from FB on a bigger screen. A bit pricey, but a good accessory to have.  Be sure to note that this is ONLY for the Nook HD and HD+ series.  It will not work with a standard Nook.'}\n",
            "Error Type: HfHubHTTPError, Message: (Request ID: Root=1-680888b3-7749bc0e5496d3222595c6e8;ba1b74c0-23a8-4773-be26-1654ef43be52)\n",
            "\n",
            "403 Forbidden: This authentication method does not have sufficient permissions to call Inference Providers on behalf of user esassom.\n",
            "Cannot access content at: https://router.huggingface.co/hf-inference/models/t5-base.\n",
            "Make sure your token has the correct permissions.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example 00d85bc8-3237-4d06-8520-f60a4a2e1844 with inputs {'review': 'Summarize this customer review:\\nI am using this with a Nook HD+. It works as described. The HD picture on my Samsung 52&#34; TV is excellent.'}\n",
            "Error Type: HfHubHTTPError, Message: (Request ID: Root=1-680888b3-26ee19d5740609701eb656b1;61e8b05b-b670-4469-bf06-83abc33385d7)\n",
            "\n",
            "403 Forbidden: This authentication method does not have sufficient permissions to call Inference Providers on behalf of user esassom.\n",
            "Cannot access content at: https://router.huggingface.co/hf-inference/models/t5-base.\n",
            "Make sure your token has the correct permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[->                                                ] 1/20\r[---->                                             ] 2/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example 005ae3ad-ee35-489d-96be-e3b4a397e200 with inputs {'review': \"Summarize this customer review:\\nIt does 2A and charges a DEAD Nook in a few hours. It does so with a LOT of heat, compared to most wall worts. I have a dual charger where 1 port is 2.1A and the other is 1A for total output of 3.1A that doesn't run as hot as this. And i use that to power a raspberry pi to avoid needing a powered hubIt does the job adequately as it's designed to. Just hot. I would always unplug it if not using (even though it cools off) because of the amount of heat made. The nook hd+ runs hot too right where you hold it on the left side in portrait, but not so much when charging. I guess it's better to have it at the plug.\"}\n",
            "Error Type: HfHubHTTPError, Message: (Request ID: Root=1-680888b3-0b2cbaae13901364136c632d;a894b804-dcc1-4ae1-9ece-fcfde7c89139)\n",
            "\n",
            "403 Forbidden: This authentication method does not have sufficient permissions to call Inference Providers on behalf of user esassom.\n",
            "Cannot access content at: https://router.huggingface.co/hf-inference/models/t5-base.\n",
            "Make sure your token has the correct permissions.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example 2db7ae44-b835-4aef-a31f-dca0613aef88 with inputs {'review': 'Summarize this customer review:\\nWorks well, a little pricey I think for a charging cable, but then again, not losing the original would be a lot cheaper than any replacement'}\n",
            "Error Type: HfHubHTTPError, Message: (Request ID: Root=1-680888b4-1348757851fcd4811ad22e53;e8da0603-56b9-4161-b4fc-822cc3025d31)\n",
            "\n",
            "403 Forbidden: This authentication method does not have sufficient permissions to call Inference Providers on behalf of user esassom.\n",
            "Cannot access content at: https://router.huggingface.co/hf-inference/models/t5-base.\n",
            "Make sure your token has the correct permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[------->                                          ] 3/20\r[--------->                                        ] 4/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example 8b3d1006-2a97-41ba-82c7-1407b108db00 with inputs {'review': 'Summarize this customer review:\\nNot going to write a long review, even thought this unit deserves one. I\\'ve driven well over 1-mil miles and done most of my own routing so I pretty know whats the fastest and shortest. Have been using a basic garmin for the past three years and with ANY Gps unit they\\'ll ALL get you in trouble if you let them. I was really excited about this unit, due to the size and the features. Allot of great grafics and on screen info thats usefull. But the most basic item that it was lacking was the gps tracking. I gave this unit allot of leadway on its mistakes due to the fact that it had allot of cool stuff that it did, but its ability to track you and route you was not even close to what the basic garmin could due. Its like the prossesor that they installed in the TND 700 was 10 years old. Example if I needed to make a simple route change I.E. in town down to the next street due to the fact that I couldn\\'t make the turn or the street was blocked off, it would take the TND 700 upwards of 45 seconds to a minute and a half to reroute me. Here I\\'m sitting at a stop light waiting for directions and waiting that long with cars on my backside didn\\'t make me happy. This is a problem that happened evertime you had to reroute, weather it was a simple street change or a major highway change. Also from the time you turned the unit on it would take twice as long to boot itself up. At least a dozen times with in a week it put me on the wrong roads and when I made a wrong turn it got it self lost....I.E. take left on xyz street, and it was some ones drive way. Or turn left in 800 yards and the turn was less than 10 feet away. You might think in a conjested city situation I might get a little mixed up, but this is out in the country. Twice it put me under 12\\'6\" bridges when I\\'m 13\\'6\". Of course I made sure all my truck setting where they were supposed to be. I also updated the OS version,via Rand McNally. All in all I expected alot out of this unit and got a unit that should of been field tested with some people that drive allot. It just had to many route mistakes. Going back to the basic garmin. This isn\\'t just my complaints, I have three friends that bought the same unit and have the same complaints. All of us returned the units.'}\n",
            "Error Type: HfHubHTTPError, Message: (Request ID: Root=1-680888b5-57f9df9e3d81b8873046e60a;f52e132f-dc3d-4376-9734-7125f46eeecd)\n",
            "\n",
            "403 Forbidden: This authentication method does not have sufficient permissions to call Inference Providers on behalf of user esassom.\n",
            "Cannot access content at: https://router.huggingface.co/hf-inference/models/t5-base.\n",
            "Make sure your token has the correct permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[----------->                                      ] 5/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example 68821ee5-6a0b-4c5d-abfb-3457695bc923 with inputs {'review': 'Summarize this customer review:\\nThis item is just as was described in the original description, works without any issues to be seen. Good product'}\n",
            "Error Type: HfHubHTTPError, Message: (Request ID: Root=1-680888b5-4c8fce3e57ac70330f66658a;8f69d1fb-0049-40c6-ae99-f501b723254c)\n",
            "\n",
            "403 Forbidden: This authentication method does not have sufficient permissions to call Inference Providers on behalf of user esassom.\n",
            "Cannot access content at: https://router.huggingface.co/hf-inference/models/t5-base.\n",
            "Make sure your token has the correct permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[-------------->                                   ] 6/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example 91339c19-0cd8-418a-9129-d46bfdc6250e with inputs {'review': \"Summarize this customer review:\\nI've had mine for a year and here's what we got. It tries to route be down non truck routes while telling me the truck route is illegal for me. This is such a bad problem that even Interstate 25 in Denver Colorado is listed (according to this GPS) as a non- truck route and will route you through the city instead. There are several drivers within our company who own one and more than half (of about 50) have crashed to an un-recoverable state. Our company representative said that Rand McNally informed them that the GPS was not designed to say on for a long period of time. Really? it's a truck driver GPS. We have one driver with a $2400 dollar ticket due to this GPS routing him down the wrong road. The companies response was to update the unit. I've had mine for a year, I never noticed one update that corrected functionality, they only seem to keep messing the tools. I want a GPS that routes, if I wanted tools I'd buy software for my computer.My suggestion is to by a nice Garmen. My one rated for cars actually routes me better than this one rated for trucks.Wayne\"}\n",
            "Error Type: HfHubHTTPError, Message: (Request ID: Root=1-680888b6-4be5e99b430621e1438e5264;f8384ee7-ecf5-447a-a643-37954d389ccf)\n",
            "\n",
            "403 Forbidden: This authentication method does not have sufficient permissions to call Inference Providers on behalf of user esassom.\n",
            "Cannot access content at: https://router.huggingface.co/hf-inference/models/t5-base.\n",
            "Make sure your token has the correct permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[----------------->                                ] 7/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example ab78b702-46a5-498f-9d58-e30f2aefdfe3 with inputs {'review': 'Summarize this customer review:\\nMy son crewed my HD charger cord so I needed another one, this is exactly like the one my son destroyed.'}\n",
            "Error Type: HfHubHTTPError, Message: (Request ID: Root=1-680888b6-6e442e1c1501cb892e6356f3;718019cd-4ba0-454a-86b4-f6ae83b8acae)\n",
            "\n",
            "403 Forbidden: This authentication method does not have sufficient permissions to call Inference Providers on behalf of user esassom.\n",
            "Cannot access content at: https://router.huggingface.co/hf-inference/models/t5-base.\n",
            "Make sure your token has the correct permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[------------------->                              ] 8/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example b2892798-7715-4148-a086-3661a96a4b3a with inputs {'review': 'Summarize this customer review:\\nbought for a spare for my 9&#34; Nook HD and it fit perfectly.  Very satisfied with the price much less than on the BN site'}\n",
            "Error Type: HfHubHTTPError, Message: (Request ID: Root=1-680888b6-2e887e537cc6dd3a6f27782e;fc258ce2-c89f-44c6-9b9e-bfc63da70737)\n",
            "\n",
            "403 Forbidden: This authentication method does not have sufficient permissions to call Inference Providers on behalf of user esassom.\n",
            "Cannot access content at: https://router.huggingface.co/hf-inference/models/t5-base.\n",
            "Make sure your token has the correct permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[--------------------->                            ] 9/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example c456879e-10a9-4a46-a8da-5b54e12316dc with inputs {'review': \"Summarize this customer review:\\nThis is a good beefy 2 amp charger, but it covers two outlets on a power strip. It's ok in a regular wall outlet. The best thing is it uses a standard USB connector so it can charge more than just a Nook (I have a Kindle Fire HD+).\"}\n",
            "Error Type: HfHubHTTPError, Message: (Request ID: Root=1-680888b8-6b07950b229970e51f9e6a97;054167e5-059f-4731-8abd-c53f03401897)\n",
            "\n",
            "403 Forbidden: This authentication method does not have sufficient permissions to call Inference Providers on behalf of user esassom.\n",
            "Cannot access content at: https://router.huggingface.co/hf-inference/models/t5-base.\n",
            "Make sure your token has the correct permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[------------------------>                         ] 10/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example da4f2c1b-22a6-457d-850e-11346f2b3fd4 with inputs {'review': \"Summarize this customer review:\\nI lost my B&N original cable.  I looked around for an new one.  I tried  a different, cheaper model but it didn't fit my device properly so back to the drawing board.  I ordered this one.  I am satisfied.  It works exactly as expected and fits perfectly.  I would recommend this product to anyone looking for a spare or in lieu of the original usb cable adapter.\"}\n",
            "Error Type: HfHubHTTPError, Message: (Request ID: Root=1-680888b9-6aa4dd776980bae60edf2231;5a63d44f-e734-46ef-be59-05efd5677649)\n",
            "\n",
            "403 Forbidden: This authentication method does not have sufficient permissions to call Inference Providers on behalf of user esassom.\n",
            "Cannot access content at: https://router.huggingface.co/hf-inference/models/t5-base.\n",
            "Make sure your token has the correct permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[--------------------------->                      ] 11/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example e696f1e6-5ca5-4c1a-abe6-4db7afdfef2d with inputs {'review': 'Summarize this customer review:\\nThis is a great buy, compared to a $60 or more a retail store.'}\n",
            "Error Type: HfHubHTTPError, Message: (Request ID: Root=1-680888ba-389e389a6fd19db97e7cd9e7;af6b1833-d79d-4d4c-80f6-01f766c649c6)\n",
            "\n",
            "403 Forbidden: This authentication method does not have sufficient permissions to call Inference Providers on behalf of user esassom.\n",
            "Cannot access content at: https://router.huggingface.co/hf-inference/models/t5-base.\n",
            "Make sure your token has the correct permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[----------------------------->                    ] 12/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example e715ce27-6ce3-48a8-9f34-bc38cd0131f3 with inputs {'review': 'Summarize this customer review:\\nI\\'m a professional OTR truck driver, and I bought a TND 700 at a truck stop hoping to make my life easier.  Rand McNally, are you listening?First thing I did after charging it was connect it to my laptop and install the software and then attempt to update it.  The software detected a problem with my update and wanted my home address so I could be sent a patch on an SD card.  Hello?  I don\\'t think I\\'m all that unusual; my home address is a PO box that a friend checks weekly and that I might get to check every six months or so.  I live in my truck and at truck stops.  If you need to make a patch available on an SD card then you should send the SD cards to the truck stops where the devices are sold.  I ran the update program multiple times until the program said that the TND 700 was completely updated.I programmed in the height (13\\'6\"), the length (53\\') and the weight (80,000#) of my rig and told it that I preferred highways.  I was parked at a truck stop in the Cincinnati OH area.  My next pickup was about 15 miles down the same freeway but on the other side of it a couple of blocks.  My cell phone GPS (Sprint) said to get on the freeway to get to my pickup.  The TND 700 routed me thru 23 miles of residential streets before finally getting me to my pickup.  Very exciting, especially since every time I refused to turn down a street posted \"No Trucks\" the TND 700 took almost 5 minutes to figure a re-route, and it happened multiple times on that short trip.I decided to give it another chance.  After my pickup on the north side of Cincinnati just off of I-75 I needed to head to Phoenix AZ via I-71.  Easy route is to just hop on I-75 and drive west and south to the intersection of I-71.  Indeed, that is what my cell phone advised.  The TND 700, however, wanted to route me over surface streets across the city and pick up I-75 on the other side of the city.  I turned it off and the next time I passed a truck stop of the same chain I purchased it at I returned it and got my money back.I then spent $30 on a cheap printer.  Now I take a minute to set up my route on Google and print it out.  Hasn\\'t gotten me lost yet over several cross country trips.'}\n",
            "Error Type: HfHubHTTPError, Message: (Request ID: Root=1-680888bb-0993863f730fb5d57a6ab8eb;eb8bfabb-c078-4292-8ebf-a44028db6206)\n",
            "\n",
            "403 Forbidden: This authentication method does not have sufficient permissions to call Inference Providers on behalf of user esassom.\n",
            "Cannot access content at: https://router.huggingface.co/hf-inference/models/t5-base.\n",
            "Make sure your token has the correct permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[------------------------------->                  ] 13/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example f4b60be0-a299-429d-9453-a5fa261f1793 with inputs {'review': 'Summarize this customer review:\\nThis mount is just what I needed.  It is strong and sturdy.  It folds almost flat to enable the television to sit square and flat against the wall if desired and extends and rotates for angle turns.  A perfect fit as long as you match the correct visa pattern for your television.'}\n",
            "Error Type: HfHubHTTPError, Message: (Request ID: Root=1-680888bc-780200fe2fa28d8b1b0b7fcd;d077def9-765a-4fde-9f66-2b076150076d)\n",
            "\n",
            "403 Forbidden: This authentication method does not have sufficient permissions to call Inference Providers on behalf of user esassom.\n",
            "Cannot access content at: https://router.huggingface.co/hf-inference/models/t5-base.\n",
            "Make sure your token has the correct permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[---------------------------------->               ] 14/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example f5dde7d5-9548-44e8-90a1-2d3d97ae50aa with inputs {'review': \"Summarize this customer review:\\nGo to Target or Barnes and Noble instead, and pay $25 (which is still a huge markup, considering they make the thing for 50 cents.) This is the worst option if you need one of these. It's price gouging, pure and simple.\"}\n",
            "Error Type: HfHubHTTPError, Message: (Request ID: Root=1-680888bd-72b0aad96b7e4ae30a11651e;2e919606-5406-4450-a34b-14e2e18194ee)\n",
            "\n",
            "403 Forbidden: This authentication method does not have sufficient permissions to call Inference Providers on behalf of user esassom.\n",
            "Cannot access content at: https://router.huggingface.co/hf-inference/models/t5-base.\n",
            "Make sure your token has the correct permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[------------------------------------->            ] 15/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example fa39d4c9-596c-46ae-8d95-4bc36a81dc39 with inputs {'review': \"Summarize this customer review:\\nWell, what can I say.  I've had this unit in my truck for about four days now.  Prior to that I had a Garmin 755T non-truck GPS.  One of my favorite features in that unit was the ability to plan a route by determining mileage using the stop or via feature.  What I would do is using a map I would route myself several different ways forcing the unit by putting in stops or vias at different locations along the route, otherwise, like most GPS 's, it determines what it thinks is the best route.  I could add up to 10 Via's or stop points for each route and then based on mileage and other factors determine which is the best route to take.  Multiple stops and the ability to route was the most important reason for having the Garmin.  However it was not truck specific.  And considering I am now hauling strictly hazmat I wanted something that would take that into consideration.  After perusing various forums, review sites, and word-of-mouth my choices boiled down to the Garmin 465T or the RAND McNally Intelliroute TND 700.  Even though it was quite a bit more than the Garmin I chose the TND 700 for several reasons.  The main one being the extra screen size, and its ability to coordinate with the RAND McNally truck atlas and also its ease of updating.Now on to my first impression of the TND 700.  It seems to be an aesthetically pleasing and durably built unit.  The first thing I noticed was it's very slow to boot compared to my old Garmin.  Whether this is unique to the TND 700 or is common amongst all truck specific gps units I cannot tell, but it's really not that big of a deal.  The second thing I noticed was the overwhelming wealth of information put forth.  That might explain why the manual (available via the TND dock) is well over 100 pages long.....  There is somewhat of a learning curve with this unit.  The next thing I noticed was the complexity of entering routes.  As previously mentioned I like to force it into my preferred routing by the use of stops or vias.  That was a big no go with this unit.  While you can enter multiple stops or vias it is nowhere near as user-friendly as my old Garmin.  Furthermore there is no way you can determine total mileage on the route that you have chosen, as I could with the Garmin.  Totally flummoxed by what appeared to be an omission of one of the best routing tools a trucker could have I went online and verified through an expert source connected with RAND McNally that no, that feature was a couple updates down the line and was not available at this point.  Unbelievable.  Also forcing the unit to follow a specific route can be very challenging.  For a unit of this price, and feature laden, I find this totally unacceptable.  I am still mulling over selling this unit  and buying the Garmin 465T.  I really do like this GPS, the screen is magnificent, and the volume is awesome.Another thing I've noticed, which I do not think is unique to this unit, is some of the weird routing that it does.  I've never owned a truck specific GPS before but after playing with this one for a couple of days I get the impression that what RAND MacNally (and the others that use Navteq) has done is take a plain old car specific Navteq map and a road atlas with truck restrictions and made notifications on the map.  In most databases there is not a 100% thorough listing of every road in the country.  What I mean is that this unit will route you down roads you don't belong on.  Today while coming home it tried routing me on several  9 ton County roads.  What that means is that a truck is limited to 73280 unless the road is posted at 10 tons.  County roads do not have that restriction listed in the RAND McNally road atlas, so I believe that is why it is not listed.....  Also unacceptable in a unit of this price and sold as truck specific.  However I'd be willing to bet the other truck specific units are the same way as no one has ever done a truck specific version of NavTeq.Another bone I have to pick is the POI's. Not only the truck specific ones but the others all seem to be somewhat outdated.  I think the Garmin, at least the ones that I have used, are more current.  It would also be nice if I could add my own POI'sTo sum it up I will keep this unit a little longer to see if I can make it workable.  If not I will go back to Garmin.  I like the concept and I like the unit but at this point I'll have to say I am somewhat unimpressed.pros:Large screenterrific imagesoutstanding volumecons:inability to determine route mileage by multiple stops and viasa somewhat outdated POI information.Non-truck specific routings.Cost.\"}\n",
            "Error Type: HfHubHTTPError, Message: (Request ID: Root=1-680888be-2ab252855b1637d05abe4fa2;37413393-b888-4357-974e-675d08d24fe8)\n",
            "\n",
            "403 Forbidden: This authentication method does not have sufficient permissions to call Inference Providers on behalf of user esassom.\n",
            "Cannot access content at: https://router.huggingface.co/hf-inference/models/t5-base.\n",
            "Make sure your token has the correct permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[--------------------------------------->          ] 16/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example 5dc83dd7-d15e-4187-8551-1ec579f77af2 with inputs {'review': 'Summarize this customer review:\\nThe cable is very wobbly and sometimes disconnects itself.The price is completely unfair and only works with the Nook HD and HD+'}\n",
            "Error Type: HfHubHTTPError, Message: (Request ID: Root=1-680888b4-5f9c6ada4c7ddd510b229767;a03cb248-3417-4fc4-b914-471c337f3a1a)\n",
            "\n",
            "403 Forbidden: This authentication method does not have sufficient permissions to call Inference Providers on behalf of user esassom.\n",
            "Cannot access content at: https://router.huggingface.co/hf-inference/models/t5-base.\n",
            "Make sure your token has the correct permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[----------------------------------------->        ] 17/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example b3b81043-1f6d-4d26-802f-7759f5aff7c7 with inputs {'review': \"Summarize this customer review:\\nThis adaptor is real easy to setup and use right out of the box. I had not problem with it at all, it is well worth the purchase. I recommend this adaptor very much for viewing your Nook videos on your HDTV. I just disagree with other reviews on the length of the adaptor, I found it to be fairly adequate as to how and where it is connected to my TV. For me it was just right not too long or too short, I was able to place my Nook right below the connection on the TV stand, it did not fall or anything else, it is fine. Use your own judgement, I'm too busy watching my movies :)\"}\n",
            "Error Type: HfHubHTTPError, Message: (Request ID: Root=1-680888b7-78c5e1a620eabf9f4c9e9b1f;ecf5fc02-a9bd-4a3c-bfc2-bae0038cafe6)\n",
            "\n",
            "403 Forbidden: This authentication method does not have sufficient permissions to call Inference Providers on behalf of user esassom.\n",
            "Cannot access content at: https://router.huggingface.co/hf-inference/models/t5-base.\n",
            "Make sure your token has the correct permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[-------------------------------------------->     ] 18/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example 4a1b846d-d05f-4889-83a6-e3d990eb18e8 with inputs {'review': 'Summarize this customer review:\\nWe got this GPS for my husband who is an (OTR) over the road trucker.  Very Impressed with the shipping time, it arrived a few days earlier than expected...  within a week of use however it started freezing up... could of just been a glitch in that unit.  Worked great when it worked!  Will work great for the normal person as well but does have the \"trucker\" option. (the big truck routes - tells you when a scale is coming up ect...)  Love the bigger screen, the ease of use, the ease of putting addresses into memory.  Nothing really bad to say about the unit with the exception of it freezing which is probably one in a million and that\\'s just my luck.  I contacted the seller and within minutes of my email I received a email back with instructions for an exchange! VERY impressed all the way around!'}\n",
            "Error Type: HfHubHTTPError, Message: (Request ID: Root=1-680888b5-1e4a902c15db1bc609f6b4f4;a109af45-4a54-4770-a28b-84afe93a1120)\n",
            "\n",
            "403 Forbidden: This authentication method does not have sufficient permissions to call Inference Providers on behalf of user esassom.\n",
            "Cannot access content at: https://router.huggingface.co/hf-inference/models/t5-base.\n",
            "Make sure your token has the correct permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[----------------------------------------------->  ] 19/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example 143c6d2d-4962-437a-9300-103d56cff9e3 with inputs {'review': 'Summarize this customer review:\\nThis product really works great but I found the following items you need to keep in mind:- You must have your power adapter connected for it to work...it plugs in the the bottom. It appears it needs power from the nook power adapter to operate.- The plug fits in loosely and you cannot move the Nook around much without holding the adapter in place.- On initial plugin it seems you need to rock it around to get the connection but then it seems solid.- It works with a 25ft high quality HDMI cable so you can put the NOOK across the room with you. Not tested with cheap cables.Warning...I found that my LG SmartTV 3D from a few years back does not work with this adapter but it does not seem to work with many things...bad software. This adapter works fine with other HDMI devices I have used like monitors and I am sure other TVs.Gave it five stars because it really is nice to extend the screen and use your Nook as a streaming server to your TV. Nice they made such a device.'}\n",
            "Error Type: HfHubHTTPError, Message: (Request ID: Root=1-680888b4-367acaf94feb5f276cacf317;14ce44e9-3ceb-4b05-8e9a-39f5227e5f45)\n",
            "\n",
            "403 Forbidden: This authentication method does not have sufficient permissions to call Inference Providers on behalf of user esassom.\n",
            "Cannot access content at: https://router.huggingface.co/hf-inference/models/t5-base.\n",
            "Make sure your token has the correct permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[------------------------------------------------->] 20/20View the evaluation results for project 'T5-FineTuned 2025-04-23 06:30:00' at:\n",
            "https://smith.langchain.com/o/fd08d518-ad5a-4f9a-8f8c-5dbc431268de/datasets/e33395c3-e366-4dcb-80fd-b3afe886321c/compare?selectedSessions=0554bd0c-ea9f-4f8b-81c2-56513c203f3b\n",
            "\n",
            "View all tests for Dataset amazon_reviews_dataset_2025-04-23 06:19:43 at:\n",
            "https://smith.langchain.com/o/fd08d518-ad5a-4f9a-8f8c-5dbc431268de/datasets/e33395c3-e366-4dcb-80fd-b3afe886321c\n",
            "[>                                                 ] 0/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example 00d85bc8-3237-4d06-8520-f60a4a2e1844 with inputs {'review': 'Summarize this customer review:\\nI am using this with a Nook HD+. It works as described. The HD picture on my Samsung 52&#34; TV is excellent.'}\n",
            "Error Type: HfHubHTTPError, Message: (Request ID: Root=1-680888ea-0595de5770d0c1fa66ea960d;cd95f145-144d-4234-bb54-6c9d519b0acd)\n",
            "\n",
            "403 Forbidden: This authentication method does not have sufficient permissions to call Inference Providers on behalf of user esassom.\n",
            "Cannot access content at: https://router.huggingface.co/hf-inference/models/flax-community/t5-base-cnn-dm.\n",
            "Make sure your token has the correct permissions.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example 48e11ae3-3535-4246-8b25-61e3516e8ccc with inputs {'review': 'Summarize this customer review:\\nThis adapter easily connects my Nook HD 7&#34; to my HDTV through the HDMI cable.  This is good for traveling because it makes any hotel TV a potential smart TV so long as there is an accessible HDMI port.  It is also good for sharing photos from FB on a bigger screen. A bit pricey, but a good accessory to have.  Be sure to note that this is ONLY for the Nook HD and HD+ series.  It will not work with a standard Nook.'}\n",
            "Error Type: HfHubHTTPError, Message: (Request ID: Root=1-680888ea-5a8fef913a66b49b3ecb102a;0f19ef4b-9159-48bc-ab51-16e04abb6162)\n",
            "\n",
            "403 Forbidden: This authentication method does not have sufficient permissions to call Inference Providers on behalf of user esassom.\n",
            "Cannot access content at: https://router.huggingface.co/hf-inference/models/flax-community/t5-base-cnn-dm.\n",
            "Make sure your token has the correct permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[->                                                ] 1/20\r[---->                                             ] 2/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example 005ae3ad-ee35-489d-96be-e3b4a397e200 with inputs {'review': \"Summarize this customer review:\\nIt does 2A and charges a DEAD Nook in a few hours. It does so with a LOT of heat, compared to most wall worts. I have a dual charger where 1 port is 2.1A and the other is 1A for total output of 3.1A that doesn't run as hot as this. And i use that to power a raspberry pi to avoid needing a powered hubIt does the job adequately as it's designed to. Just hot. I would always unplug it if not using (even though it cools off) because of the amount of heat made. The nook hd+ runs hot too right where you hold it on the left side in portrait, but not so much when charging. I guess it's better to have it at the plug.\"}\n",
            "Error Type: HfHubHTTPError, Message: (Request ID: Root=1-680888ea-36c342900461acdf6e7c00a1;d9979102-1451-4d42-b14e-afde94e6932e)\n",
            "\n",
            "403 Forbidden: This authentication method does not have sufficient permissions to call Inference Providers on behalf of user esassom.\n",
            "Cannot access content at: https://router.huggingface.co/hf-inference/models/flax-community/t5-base-cnn-dm.\n",
            "Make sure your token has the correct permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[------->                                          ] 3/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example 68821ee5-6a0b-4c5d-abfb-3457695bc923 with inputs {'review': 'Summarize this customer review:\\nThis item is just as was described in the original description, works without any issues to be seen. Good product'}\n",
            "Error Type: HfHubHTTPError, Message: (Request ID: Root=1-680888ec-5600bb883aed99c719ac15f7;8bf6df8f-bbea-4b37-8ada-e0abf78fea62)\n",
            "\n",
            "403 Forbidden: This authentication method does not have sufficient permissions to call Inference Providers on behalf of user esassom.\n",
            "Cannot access content at: https://router.huggingface.co/hf-inference/models/flax-community/t5-base-cnn-dm.\n",
            "Make sure your token has the correct permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[--------->                                        ] 4/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example 5dc83dd7-d15e-4187-8551-1ec579f77af2 with inputs {'review': 'Summarize this customer review:\\nThe cable is very wobbly and sometimes disconnects itself.The price is completely unfair and only works with the Nook HD and HD+'}\n",
            "Error Type: HfHubHTTPError, Message: (Request ID: Root=1-680888eb-60220ccd79390c0a42024b51;de31eb8f-625a-4044-8074-defd3f7ca3c8)\n",
            "\n",
            "403 Forbidden: This authentication method does not have sufficient permissions to call Inference Providers on behalf of user esassom.\n",
            "Cannot access content at: https://router.huggingface.co/hf-inference/models/flax-community/t5-base-cnn-dm.\n",
            "Make sure your token has the correct permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[----------->                                      ] 5/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example 91339c19-0cd8-418a-9129-d46bfdc6250e with inputs {'review': \"Summarize this customer review:\\nI've had mine for a year and here's what we got. It tries to route be down non truck routes while telling me the truck route is illegal for me. This is such a bad problem that even Interstate 25 in Denver Colorado is listed (according to this GPS) as a non- truck route and will route you through the city instead. There are several drivers within our company who own one and more than half (of about 50) have crashed to an un-recoverable state. Our company representative said that Rand McNally informed them that the GPS was not designed to say on for a long period of time. Really? it's a truck driver GPS. We have one driver with a $2400 dollar ticket due to this GPS routing him down the wrong road. The companies response was to update the unit. I've had mine for a year, I never noticed one update that corrected functionality, they only seem to keep messing the tools. I want a GPS that routes, if I wanted tools I'd buy software for my computer.My suggestion is to by a nice Garmen. My one rated for cars actually routes me better than this one rated for trucks.Wayne\"}\n",
            "Error Type: HfHubHTTPError, Message: (Request ID: Root=1-680888f2-61307b625935b9bf43b90b8a;79048245-9894-45ed-95bc-d8ee73715c00)\n",
            "\n",
            "403 Forbidden: This authentication method does not have sufficient permissions to call Inference Providers on behalf of user esassom.\n",
            "Cannot access content at: https://router.huggingface.co/hf-inference/models/flax-community/t5-base-cnn-dm.\n",
            "Make sure your token has the correct permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[-------------->                                   ] 6/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example ab78b702-46a5-498f-9d58-e30f2aefdfe3 with inputs {'review': 'Summarize this customer review:\\nMy son crewed my HD charger cord so I needed another one, this is exactly like the one my son destroyed.'}\n",
            "Error Type: HfHubHTTPError, Message: (Request ID: Root=1-680888f3-5b71a8905dfb668723e4c4c7;8ce1b868-5e6a-4d80-9582-0f33de780cba)\n",
            "\n",
            "403 Forbidden: This authentication method does not have sufficient permissions to call Inference Providers on behalf of user esassom.\n",
            "Cannot access content at: https://router.huggingface.co/hf-inference/models/flax-community/t5-base-cnn-dm.\n",
            "Make sure your token has the correct permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[----------------->                                ] 7/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example b2892798-7715-4148-a086-3661a96a4b3a with inputs {'review': 'Summarize this customer review:\\nbought for a spare for my 9&#34; Nook HD and it fit perfectly.  Very satisfied with the price much less than on the BN site'}\n",
            "Error Type: HfHubHTTPError, Message: (Request ID: Root=1-680888f4-7baaee28150ba964610edcfb;4cbf04ec-e98a-4af0-afd3-4aded2c61c25)\n",
            "\n",
            "403 Forbidden: This authentication method does not have sufficient permissions to call Inference Providers on behalf of user esassom.\n",
            "Cannot access content at: https://router.huggingface.co/hf-inference/models/flax-community/t5-base-cnn-dm.\n",
            "Make sure your token has the correct permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[------------------->                              ] 8/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example b3b81043-1f6d-4d26-802f-7759f5aff7c7 with inputs {'review': \"Summarize this customer review:\\nThis adaptor is real easy to setup and use right out of the box. I had not problem with it at all, it is well worth the purchase. I recommend this adaptor very much for viewing your Nook videos on your HDTV. I just disagree with other reviews on the length of the adaptor, I found it to be fairly adequate as to how and where it is connected to my TV. For me it was just right not too long or too short, I was able to place my Nook right below the connection on the TV stand, it did not fall or anything else, it is fine. Use your own judgement, I'm too busy watching my movies :)\"}\n",
            "Error Type: HfHubHTTPError, Message: (Request ID: Root=1-680888f5-5ba1717b4d1aefa90cb2ec71;4800dc19-4d49-49fe-bef1-4eb9b663a2c8)\n",
            "\n",
            "403 Forbidden: This authentication method does not have sufficient permissions to call Inference Providers on behalf of user esassom.\n",
            "Cannot access content at: https://router.huggingface.co/hf-inference/models/flax-community/t5-base-cnn-dm.\n",
            "Make sure your token has the correct permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[--------------------->                            ] 9/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example c456879e-10a9-4a46-a8da-5b54e12316dc with inputs {'review': \"Summarize this customer review:\\nThis is a good beefy 2 amp charger, but it covers two outlets on a power strip. It's ok in a regular wall outlet. The best thing is it uses a standard USB connector so it can charge more than just a Nook (I have a Kindle Fire HD+).\"}\n",
            "Error Type: HfHubHTTPError, Message: (Request ID: Root=1-680888f6-1076e394155d343c3c498b00;81565329-5b24-49ea-85f0-4c797c55a1f2)\n",
            "\n",
            "403 Forbidden: This authentication method does not have sufficient permissions to call Inference Providers on behalf of user esassom.\n",
            "Cannot access content at: https://router.huggingface.co/hf-inference/models/flax-community/t5-base-cnn-dm.\n",
            "Make sure your token has the correct permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[------------------------>                         ] 10/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example 4a1b846d-d05f-4889-83a6-e3d990eb18e8 with inputs {'review': 'Summarize this customer review:\\nWe got this GPS for my husband who is an (OTR) over the road trucker.  Very Impressed with the shipping time, it arrived a few days earlier than expected...  within a week of use however it started freezing up... could of just been a glitch in that unit.  Worked great when it worked!  Will work great for the normal person as well but does have the \"trucker\" option. (the big truck routes - tells you when a scale is coming up ect...)  Love the bigger screen, the ease of use, the ease of putting addresses into memory.  Nothing really bad to say about the unit with the exception of it freezing which is probably one in a million and that\\'s just my luck.  I contacted the seller and within minutes of my email I received a email back with instructions for an exchange! VERY impressed all the way around!'}\n",
            "Error Type: HfHubHTTPError, Message: (Request ID: Root=1-680888eb-4b0d49ba6a4a9b287c50d34d;2736c4a6-9f0c-4959-b8da-df08c7666419)\n",
            "\n",
            "403 Forbidden: This authentication method does not have sufficient permissions to call Inference Providers on behalf of user esassom.\n",
            "Cannot access content at: https://router.huggingface.co/hf-inference/models/flax-community/t5-base-cnn-dm.\n",
            "Make sure your token has the correct permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[--------------------------->                      ] 11/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example da4f2c1b-22a6-457d-850e-11346f2b3fd4 with inputs {'review': \"Summarize this customer review:\\nI lost my B&N original cable.  I looked around for an new one.  I tried  a different, cheaper model but it didn't fit my device properly so back to the drawing board.  I ordered this one.  I am satisfied.  It works exactly as expected and fits perfectly.  I would recommend this product to anyone looking for a spare or in lieu of the original usb cable adapter.\"}\n",
            "Error Type: HfHubHTTPError, Message: (Request ID: Root=1-680888f7-6e8346cd5b1b28865db4f50d;bef4559e-3d50-4362-8cfd-2ce8fd8e0845)\n",
            "\n",
            "403 Forbidden: This authentication method does not have sufficient permissions to call Inference Providers on behalf of user esassom.\n",
            "Cannot access content at: https://router.huggingface.co/hf-inference/models/flax-community/t5-base-cnn-dm.\n",
            "Make sure your token has the correct permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[----------------------------->                    ] 12/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example e696f1e6-5ca5-4c1a-abe6-4db7afdfef2d with inputs {'review': 'Summarize this customer review:\\nThis is a great buy, compared to a $60 or more a retail store.'}\n",
            "Error Type: HfHubHTTPError, Message: (Request ID: Root=1-680888f8-202e2da21b9950157d9f5c27;a638e8d6-8d91-4cd4-8260-6ee6bcc7e0ed)\n",
            "\n",
            "403 Forbidden: This authentication method does not have sufficient permissions to call Inference Providers on behalf of user esassom.\n",
            "Cannot access content at: https://router.huggingface.co/hf-inference/models/flax-community/t5-base-cnn-dm.\n",
            "Make sure your token has the correct permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[------------------------------->                  ] 13/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example e715ce27-6ce3-48a8-9f34-bc38cd0131f3 with inputs {'review': 'Summarize this customer review:\\nI\\'m a professional OTR truck driver, and I bought a TND 700 at a truck stop hoping to make my life easier.  Rand McNally, are you listening?First thing I did after charging it was connect it to my laptop and install the software and then attempt to update it.  The software detected a problem with my update and wanted my home address so I could be sent a patch on an SD card.  Hello?  I don\\'t think I\\'m all that unusual; my home address is a PO box that a friend checks weekly and that I might get to check every six months or so.  I live in my truck and at truck stops.  If you need to make a patch available on an SD card then you should send the SD cards to the truck stops where the devices are sold.  I ran the update program multiple times until the program said that the TND 700 was completely updated.I programmed in the height (13\\'6\"), the length (53\\') and the weight (80,000#) of my rig and told it that I preferred highways.  I was parked at a truck stop in the Cincinnati OH area.  My next pickup was about 15 miles down the same freeway but on the other side of it a couple of blocks.  My cell phone GPS (Sprint) said to get on the freeway to get to my pickup.  The TND 700 routed me thru 23 miles of residential streets before finally getting me to my pickup.  Very exciting, especially since every time I refused to turn down a street posted \"No Trucks\" the TND 700 took almost 5 minutes to figure a re-route, and it happened multiple times on that short trip.I decided to give it another chance.  After my pickup on the north side of Cincinnati just off of I-75 I needed to head to Phoenix AZ via I-71.  Easy route is to just hop on I-75 and drive west and south to the intersection of I-71.  Indeed, that is what my cell phone advised.  The TND 700, however, wanted to route me over surface streets across the city and pick up I-75 on the other side of the city.  I turned it off and the next time I passed a truck stop of the same chain I purchased it at I returned it and got my money back.I then spent $30 on a cheap printer.  Now I take a minute to set up my route on Google and print it out.  Hasn\\'t gotten me lost yet over several cross country trips.'}\n",
            "Error Type: HfHubHTTPError, Message: (Request ID: Root=1-680888f8-30c6404912e304f47d6610c9;29b96134-4c07-4293-aeba-f28fe1478cf4)\n",
            "\n",
            "403 Forbidden: This authentication method does not have sufficient permissions to call Inference Providers on behalf of user esassom.\n",
            "Cannot access content at: https://router.huggingface.co/hf-inference/models/flax-community/t5-base-cnn-dm.\n",
            "Make sure your token has the correct permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[---------------------------------->               ] 14/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example f4b60be0-a299-429d-9453-a5fa261f1793 with inputs {'review': 'Summarize this customer review:\\nThis mount is just what I needed.  It is strong and sturdy.  It folds almost flat to enable the television to sit square and flat against the wall if desired and extends and rotates for angle turns.  A perfect fit as long as you match the correct visa pattern for your television.'}\n",
            "Error Type: HfHubHTTPError, Message: (Request ID: Root=1-680888f9-4775a725105f6774634a2f19;3d0810c1-baa5-4b6e-b067-3f67eb8a4153)\n",
            "\n",
            "403 Forbidden: This authentication method does not have sufficient permissions to call Inference Providers on behalf of user esassom.\n",
            "Cannot access content at: https://router.huggingface.co/hf-inference/models/flax-community/t5-base-cnn-dm.\n",
            "Make sure your token has the correct permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[------------------------------------->            ] 15/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example fa39d4c9-596c-46ae-8d95-4bc36a81dc39 with inputs {'review': \"Summarize this customer review:\\nWell, what can I say.  I've had this unit in my truck for about four days now.  Prior to that I had a Garmin 755T non-truck GPS.  One of my favorite features in that unit was the ability to plan a route by determining mileage using the stop or via feature.  What I would do is using a map I would route myself several different ways forcing the unit by putting in stops or vias at different locations along the route, otherwise, like most GPS 's, it determines what it thinks is the best route.  I could add up to 10 Via's or stop points for each route and then based on mileage and other factors determine which is the best route to take.  Multiple stops and the ability to route was the most important reason for having the Garmin.  However it was not truck specific.  And considering I am now hauling strictly hazmat I wanted something that would take that into consideration.  After perusing various forums, review sites, and word-of-mouth my choices boiled down to the Garmin 465T or the RAND McNally Intelliroute TND 700.  Even though it was quite a bit more than the Garmin I chose the TND 700 for several reasons.  The main one being the extra screen size, and its ability to coordinate with the RAND McNally truck atlas and also its ease of updating.Now on to my first impression of the TND 700.  It seems to be an aesthetically pleasing and durably built unit.  The first thing I noticed was it's very slow to boot compared to my old Garmin.  Whether this is unique to the TND 700 or is common amongst all truck specific gps units I cannot tell, but it's really not that big of a deal.  The second thing I noticed was the overwhelming wealth of information put forth.  That might explain why the manual (available via the TND dock) is well over 100 pages long.....  There is somewhat of a learning curve with this unit.  The next thing I noticed was the complexity of entering routes.  As previously mentioned I like to force it into my preferred routing by the use of stops or vias.  That was a big no go with this unit.  While you can enter multiple stops or vias it is nowhere near as user-friendly as my old Garmin.  Furthermore there is no way you can determine total mileage on the route that you have chosen, as I could with the Garmin.  Totally flummoxed by what appeared to be an omission of one of the best routing tools a trucker could have I went online and verified through an expert source connected with RAND McNally that no, that feature was a couple updates down the line and was not available at this point.  Unbelievable.  Also forcing the unit to follow a specific route can be very challenging.  For a unit of this price, and feature laden, I find this totally unacceptable.  I am still mulling over selling this unit  and buying the Garmin 465T.  I really do like this GPS, the screen is magnificent, and the volume is awesome.Another thing I've noticed, which I do not think is unique to this unit, is some of the weird routing that it does.  I've never owned a truck specific GPS before but after playing with this one for a couple of days I get the impression that what RAND MacNally (and the others that use Navteq) has done is take a plain old car specific Navteq map and a road atlas with truck restrictions and made notifications on the map.  In most databases there is not a 100% thorough listing of every road in the country.  What I mean is that this unit will route you down roads you don't belong on.  Today while coming home it tried routing me on several  9 ton County roads.  What that means is that a truck is limited to 73280 unless the road is posted at 10 tons.  County roads do not have that restriction listed in the RAND McNally road atlas, so I believe that is why it is not listed.....  Also unacceptable in a unit of this price and sold as truck specific.  However I'd be willing to bet the other truck specific units are the same way as no one has ever done a truck specific version of NavTeq.Another bone I have to pick is the POI's. Not only the truck specific ones but the others all seem to be somewhat outdated.  I think the Garmin, at least the ones that I have used, are more current.  It would also be nice if I could add my own POI'sTo sum it up I will keep this unit a little longer to see if I can make it workable.  If not I will go back to Garmin.  I like the concept and I like the unit but at this point I'll have to say I am somewhat unimpressed.pros:Large screenterrific imagesoutstanding volumecons:inability to determine route mileage by multiple stops and viasa somewhat outdated POI information.Non-truck specific routings.Cost.\"}\n",
            "Error Type: HfHubHTTPError, Message: (Request ID: Root=1-680888f9-5c6804ef0b730aa274ee2ede;7d00f3f7-8a27-4adf-92bd-dd1ed6455f9a)\n",
            "\n",
            "403 Forbidden: This authentication method does not have sufficient permissions to call Inference Providers on behalf of user esassom.\n",
            "Cannot access content at: https://router.huggingface.co/hf-inference/models/flax-community/t5-base-cnn-dm.\n",
            "Make sure your token has the correct permissions.\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example f5dde7d5-9548-44e8-90a1-2d3d97ae50aa with inputs {'review': \"Summarize this customer review:\\nGo to Target or Barnes and Noble instead, and pay $25 (which is still a huge markup, considering they make the thing for 50 cents.) This is the worst option if you need one of these. It's price gouging, pure and simple.\"}\n",
            "Error Type: HfHubHTTPError, Message: (Request ID: Root=1-680888f9-1250b9955ad6fd9459b20fb5;201929d9-78b5-4b54-aa4b-d1243082dc4f)\n",
            "\n",
            "403 Forbidden: This authentication method does not have sufficient permissions to call Inference Providers on behalf of user esassom.\n",
            "Cannot access content at: https://router.huggingface.co/hf-inference/models/flax-community/t5-base-cnn-dm.\n",
            "Make sure your token has the correct permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[--------------------------------------->          ] 16/20\r[----------------------------------------->        ] 17/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example 143c6d2d-4962-437a-9300-103d56cff9e3 with inputs {'review': 'Summarize this customer review:\\nThis product really works great but I found the following items you need to keep in mind:- You must have your power adapter connected for it to work...it plugs in the the bottom. It appears it needs power from the nook power adapter to operate.- The plug fits in loosely and you cannot move the Nook around much without holding the adapter in place.- On initial plugin it seems you need to rock it around to get the connection but then it seems solid.- It works with a 25ft high quality HDMI cable so you can put the NOOK across the room with you. Not tested with cheap cables.Warning...I found that my LG SmartTV 3D from a few years back does not work with this adapter but it does not seem to work with many things...bad software. This adapter works fine with other HDMI devices I have used like monitors and I am sure other TVs.Gave it five stars because it really is nice to extend the screen and use your Nook as a streaming server to your TV. Nice they made such a device.'}\n",
            "Error Type: HfHubHTTPError, Message: (Request ID: Root=1-680888ea-0ad6ac8c221c5a124771f36c;f62853ab-9726-4f34-a137-e179c27f1aec)\n",
            "\n",
            "403 Forbidden: This authentication method does not have sufficient permissions to call Inference Providers on behalf of user esassom.\n",
            "Cannot access content at: https://router.huggingface.co/hf-inference/models/flax-community/t5-base-cnn-dm.\n",
            "Make sure your token has the correct permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[-------------------------------------------->     ] 18/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example 2db7ae44-b835-4aef-a31f-dca0613aef88 with inputs {'review': 'Summarize this customer review:\\nWorks well, a little pricey I think for a charging cable, but then again, not losing the original would be a lot cheaper than any replacement'}\n",
            "Error Type: HfHubHTTPError, Message: (Request ID: Root=1-680888ea-48df15602cb5d49f4b1866ab;0879f26c-8856-4456-9e8c-77c83c627430)\n",
            "\n",
            "403 Forbidden: This authentication method does not have sufficient permissions to call Inference Providers on behalf of user esassom.\n",
            "Cannot access content at: https://router.huggingface.co/hf-inference/models/flax-community/t5-base-cnn-dm.\n",
            "Make sure your token has the correct permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[----------------------------------------------->  ] 19/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example 8b3d1006-2a97-41ba-82c7-1407b108db00 with inputs {'review': 'Summarize this customer review:\\nNot going to write a long review, even thought this unit deserves one. I\\'ve driven well over 1-mil miles and done most of my own routing so I pretty know whats the fastest and shortest. Have been using a basic garmin for the past three years and with ANY Gps unit they\\'ll ALL get you in trouble if you let them. I was really excited about this unit, due to the size and the features. Allot of great grafics and on screen info thats usefull. But the most basic item that it was lacking was the gps tracking. I gave this unit allot of leadway on its mistakes due to the fact that it had allot of cool stuff that it did, but its ability to track you and route you was not even close to what the basic garmin could due. Its like the prossesor that they installed in the TND 700 was 10 years old. Example if I needed to make a simple route change I.E. in town down to the next street due to the fact that I couldn\\'t make the turn or the street was blocked off, it would take the TND 700 upwards of 45 seconds to a minute and a half to reroute me. Here I\\'m sitting at a stop light waiting for directions and waiting that long with cars on my backside didn\\'t make me happy. This is a problem that happened evertime you had to reroute, weather it was a simple street change or a major highway change. Also from the time you turned the unit on it would take twice as long to boot itself up. At least a dozen times with in a week it put me on the wrong roads and when I made a wrong turn it got it self lost....I.E. take left on xyz street, and it was some ones drive way. Or turn left in 800 yards and the turn was less than 10 feet away. You might think in a conjested city situation I might get a little mixed up, but this is out in the country. Twice it put me under 12\\'6\" bridges when I\\'m 13\\'6\". Of course I made sure all my truck setting where they were supposed to be. I also updated the OS version,via Rand McNally. All in all I expected alot out of this unit and got a unit that should of been field tested with some people that drive allot. It just had to many route mistakes. Going back to the basic garmin. This isn\\'t just my complaints, I have three friends that bought the same unit and have the same complaints. All of us returned the units.'}\n",
            "Error Type: HfHubHTTPError, Message: (Request ID: Root=1-680888ed-29ee66ef0d8b04fb0506308a;4f21c159-fbec-4831-ac67-526b2f54917e)\n",
            "\n",
            "403 Forbidden: This authentication method does not have sufficient permissions to call Inference Providers on behalf of user esassom.\n",
            "Cannot access content at: https://router.huggingface.co/hf-inference/models/flax-community/t5-base-cnn-dm.\n",
            "Make sure your token has the correct permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[------------------------------------------------->] 20/20View the evaluation results for project 'OpenAI 2025-04-23 06:30:45' at:\n",
            "https://smith.langchain.com/o/fd08d518-ad5a-4f9a-8f8c-5dbc431268de/datasets/e33395c3-e366-4dcb-80fd-b3afe886321c/compare?selectedSessions=6ff7b631-e18d-4493-a1e5-99c7e0d5ad24\n",
            "\n",
            "View all tests for Dataset amazon_reviews_dataset_2025-04-23 06:19:43 at:\n",
            "https://smith.langchain.com/o/fd08d518-ad5a-4f9a-8f8c-5dbc431268de/datasets/e33395c3-e366-4dcb-80fd-b3afe886321c\n",
            "[>                                                 ] 0/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example 143c6d2d-4962-437a-9300-103d56cff9e3 with inputs {'review': 'Summarize this customer review:\\nThis product really works great but I found the following items you need to keep in mind:- You must have your power adapter connected for it to work...it plugs in the the bottom. It appears it needs power from the nook power adapter to operate.- The plug fits in loosely and you cannot move the Nook around much without holding the adapter in place.- On initial plugin it seems you need to rock it around to get the connection but then it seems solid.- It works with a 25ft high quality HDMI cable so you can put the NOOK across the room with you. Not tested with cheap cables.Warning...I found that my LG SmartTV 3D from a few years back does not work with this adapter but it does not seem to work with many things...bad software. This adapter works fine with other HDMI devices I have used like monitors and I am sure other TVs.Gave it five stars because it really is nice to extend the screen and use your Nook as a streaming server to your TV. Nice they made such a device.'}\n",
            "Error Type: AuthenticationError, Message: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-****************************************************************************************************************************************************************************************************************************************0fd9. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example 00d85bc8-3237-4d06-8520-f60a4a2e1844 with inputs {'review': 'Summarize this customer review:\\nI am using this with a Nook HD+. It works as described. The HD picture on my Samsung 52&#34; TV is excellent.'}\n",
            "Error Type: AuthenticationError, Message: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-****************************************************************************************************************************************************************************************************************************************0fd9. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[->                                                ] 1/20\r[---->                                             ] 2/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example 48e11ae3-3535-4246-8b25-61e3516e8ccc with inputs {'review': 'Summarize this customer review:\\nThis adapter easily connects my Nook HD 7&#34; to my HDTV through the HDMI cable.  This is good for traveling because it makes any hotel TV a potential smart TV so long as there is an accessible HDMI port.  It is also good for sharing photos from FB on a bigger screen. A bit pricey, but a good accessory to have.  Be sure to note that this is ONLY for the Nook HD and HD+ series.  It will not work with a standard Nook.'}\n",
            "Error Type: AuthenticationError, Message: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-****************************************************************************************************************************************************************************************************************************************0fd9. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example 2db7ae44-b835-4aef-a31f-dca0613aef88 with inputs {'review': 'Summarize this customer review:\\nWorks well, a little pricey I think for a charging cable, but then again, not losing the original would be a lot cheaper than any replacement'}\n",
            "Error Type: AuthenticationError, Message: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-****************************************************************************************************************************************************************************************************************************************0fd9. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[------->                                          ] 3/20\r[--------->                                        ] 4/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example 4a1b846d-d05f-4889-83a6-e3d990eb18e8 with inputs {'review': 'Summarize this customer review:\\nWe got this GPS for my husband who is an (OTR) over the road trucker.  Very Impressed with the shipping time, it arrived a few days earlier than expected...  within a week of use however it started freezing up... could of just been a glitch in that unit.  Worked great when it worked!  Will work great for the normal person as well but does have the \"trucker\" option. (the big truck routes - tells you when a scale is coming up ect...)  Love the bigger screen, the ease of use, the ease of putting addresses into memory.  Nothing really bad to say about the unit with the exception of it freezing which is probably one in a million and that\\'s just my luck.  I contacted the seller and within minutes of my email I received a email back with instructions for an exchange! VERY impressed all the way around!'}\n",
            "Error Type: AuthenticationError, Message: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-****************************************************************************************************************************************************************************************************************************************0fd9. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[----------->                                      ] 5/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example 68821ee5-6a0b-4c5d-abfb-3457695bc923 with inputs {'review': 'Summarize this customer review:\\nThis item is just as was described in the original description, works without any issues to be seen. Good product'}\n",
            "Error Type: AuthenticationError, Message: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-****************************************************************************************************************************************************************************************************************************************0fd9. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[-------------->                                   ] 6/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example ab78b702-46a5-498f-9d58-e30f2aefdfe3 with inputs {'review': 'Summarize this customer review:\\nMy son crewed my HD charger cord so I needed another one, this is exactly like the one my son destroyed.'}\n",
            "Error Type: AuthenticationError, Message: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-****************************************************************************************************************************************************************************************************************************************0fd9. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example 91339c19-0cd8-418a-9129-d46bfdc6250e with inputs {'review': \"Summarize this customer review:\\nI've had mine for a year and here's what we got. It tries to route be down non truck routes while telling me the truck route is illegal for me. This is such a bad problem that even Interstate 25 in Denver Colorado is listed (according to this GPS) as a non- truck route and will route you through the city instead. There are several drivers within our company who own one and more than half (of about 50) have crashed to an un-recoverable state. Our company representative said that Rand McNally informed them that the GPS was not designed to say on for a long period of time. Really? it's a truck driver GPS. We have one driver with a $2400 dollar ticket due to this GPS routing him down the wrong road. The companies response was to update the unit. I've had mine for a year, I never noticed one update that corrected functionality, they only seem to keep messing the tools. I want a GPS that routes, if I wanted tools I'd buy software for my computer.My suggestion is to by a nice Garmen. My one rated for cars actually routes me better than this one rated for trucks.Wayne\"}\n",
            "Error Type: AuthenticationError, Message: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-****************************************************************************************************************************************************************************************************************************************0fd9. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[----------------->                                ] 7/20\r[------------------->                              ] 8/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example b2892798-7715-4148-a086-3661a96a4b3a with inputs {'review': 'Summarize this customer review:\\nbought for a spare for my 9&#34; Nook HD and it fit perfectly.  Very satisfied with the price much less than on the BN site'}\n",
            "Error Type: AuthenticationError, Message: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-****************************************************************************************************************************************************************************************************************************************0fd9. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[--------------------->                            ] 9/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example b3b81043-1f6d-4d26-802f-7759f5aff7c7 with inputs {'review': \"Summarize this customer review:\\nThis adaptor is real easy to setup and use right out of the box. I had not problem with it at all, it is well worth the purchase. I recommend this adaptor very much for viewing your Nook videos on your HDTV. I just disagree with other reviews on the length of the adaptor, I found it to be fairly adequate as to how and where it is connected to my TV. For me it was just right not too long or too short, I was able to place my Nook right below the connection on the TV stand, it did not fall or anything else, it is fine. Use your own judgement, I'm too busy watching my movies :)\"}\n",
            "Error Type: AuthenticationError, Message: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-****************************************************************************************************************************************************************************************************************************************0fd9. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[------------------------>                         ] 10/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example c456879e-10a9-4a46-a8da-5b54e12316dc with inputs {'review': \"Summarize this customer review:\\nThis is a good beefy 2 amp charger, but it covers two outlets on a power strip. It's ok in a regular wall outlet. The best thing is it uses a standard USB connector so it can charge more than just a Nook (I have a Kindle Fire HD+).\"}\n",
            "Error Type: AuthenticationError, Message: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-****************************************************************************************************************************************************************************************************************************************0fd9. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[--------------------------->                      ] 11/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example da4f2c1b-22a6-457d-850e-11346f2b3fd4 with inputs {'review': \"Summarize this customer review:\\nI lost my B&N original cable.  I looked around for an new one.  I tried  a different, cheaper model but it didn't fit my device properly so back to the drawing board.  I ordered this one.  I am satisfied.  It works exactly as expected and fits perfectly.  I would recommend this product to anyone looking for a spare or in lieu of the original usb cable adapter.\"}\n",
            "Error Type: AuthenticationError, Message: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-****************************************************************************************************************************************************************************************************************************************0fd9. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[----------------------------->                    ] 12/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example 005ae3ad-ee35-489d-96be-e3b4a397e200 with inputs {'review': \"Summarize this customer review:\\nIt does 2A and charges a DEAD Nook in a few hours. It does so with a LOT of heat, compared to most wall worts. I have a dual charger where 1 port is 2.1A and the other is 1A for total output of 3.1A that doesn't run as hot as this. And i use that to power a raspberry pi to avoid needing a powered hubIt does the job adequately as it's designed to. Just hot. I would always unplug it if not using (even though it cools off) because of the amount of heat made. The nook hd+ runs hot too right where you hold it on the left side in portrait, but not so much when charging. I guess it's better to have it at the plug.\"}\n",
            "Error Type: AuthenticationError, Message: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-****************************************************************************************************************************************************************************************************************************************0fd9. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example e696f1e6-5ca5-4c1a-abe6-4db7afdfef2d with inputs {'review': 'Summarize this customer review:\\nThis is a great buy, compared to a $60 or more a retail store.'}\n",
            "Error Type: AuthenticationError, Message: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-****************************************************************************************************************************************************************************************************************************************0fd9. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[------------------------------->                  ] 13/20\r[---------------------------------->               ] 14/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example f4b60be0-a299-429d-9453-a5fa261f1793 with inputs {'review': 'Summarize this customer review:\\nThis mount is just what I needed.  It is strong and sturdy.  It folds almost flat to enable the television to sit square and flat against the wall if desired and extends and rotates for angle turns.  A perfect fit as long as you match the correct visa pattern for your television.'}\n",
            "Error Type: AuthenticationError, Message: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-****************************************************************************************************************************************************************************************************************************************0fd9. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[------------------------------------->            ] 15/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example f5dde7d5-9548-44e8-90a1-2d3d97ae50aa with inputs {'review': \"Summarize this customer review:\\nGo to Target or Barnes and Noble instead, and pay $25 (which is still a huge markup, considering they make the thing for 50 cents.) This is the worst option if you need one of these. It's price gouging, pure and simple.\"}\n",
            "Error Type: AuthenticationError, Message: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-****************************************************************************************************************************************************************************************************************************************0fd9. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[--------------------------------------->          ] 16/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example 8b3d1006-2a97-41ba-82c7-1407b108db00 with inputs {'review': 'Summarize this customer review:\\nNot going to write a long review, even thought this unit deserves one. I\\'ve driven well over 1-mil miles and done most of my own routing so I pretty know whats the fastest and shortest. Have been using a basic garmin for the past three years and with ANY Gps unit they\\'ll ALL get you in trouble if you let them. I was really excited about this unit, due to the size and the features. Allot of great grafics and on screen info thats usefull. But the most basic item that it was lacking was the gps tracking. I gave this unit allot of leadway on its mistakes due to the fact that it had allot of cool stuff that it did, but its ability to track you and route you was not even close to what the basic garmin could due. Its like the prossesor that they installed in the TND 700 was 10 years old. Example if I needed to make a simple route change I.E. in town down to the next street due to the fact that I couldn\\'t make the turn or the street was blocked off, it would take the TND 700 upwards of 45 seconds to a minute and a half to reroute me. Here I\\'m sitting at a stop light waiting for directions and waiting that long with cars on my backside didn\\'t make me happy. This is a problem that happened evertime you had to reroute, weather it was a simple street change or a major highway change. Also from the time you turned the unit on it would take twice as long to boot itself up. At least a dozen times with in a week it put me on the wrong roads and when I made a wrong turn it got it self lost....I.E. take left on xyz street, and it was some ones drive way. Or turn left in 800 yards and the turn was less than 10 feet away. You might think in a conjested city situation I might get a little mixed up, but this is out in the country. Twice it put me under 12\\'6\" bridges when I\\'m 13\\'6\". Of course I made sure all my truck setting where they were supposed to be. I also updated the OS version,via Rand McNally. All in all I expected alot out of this unit and got a unit that should of been field tested with some people that drive allot. It just had to many route mistakes. Going back to the basic garmin. This isn\\'t just my complaints, I have three friends that bought the same unit and have the same complaints. All of us returned the units.'}\n",
            "Error Type: AuthenticationError, Message: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-****************************************************************************************************************************************************************************************************************************************0fd9. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[----------------------------------------->        ] 17/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example e715ce27-6ce3-48a8-9f34-bc38cd0131f3 with inputs {'review': 'Summarize this customer review:\\nI\\'m a professional OTR truck driver, and I bought a TND 700 at a truck stop hoping to make my life easier.  Rand McNally, are you listening?First thing I did after charging it was connect it to my laptop and install the software and then attempt to update it.  The software detected a problem with my update and wanted my home address so I could be sent a patch on an SD card.  Hello?  I don\\'t think I\\'m all that unusual; my home address is a PO box that a friend checks weekly and that I might get to check every six months or so.  I live in my truck and at truck stops.  If you need to make a patch available on an SD card then you should send the SD cards to the truck stops where the devices are sold.  I ran the update program multiple times until the program said that the TND 700 was completely updated.I programmed in the height (13\\'6\"), the length (53\\') and the weight (80,000#) of my rig and told it that I preferred highways.  I was parked at a truck stop in the Cincinnati OH area.  My next pickup was about 15 miles down the same freeway but on the other side of it a couple of blocks.  My cell phone GPS (Sprint) said to get on the freeway to get to my pickup.  The TND 700 routed me thru 23 miles of residential streets before finally getting me to my pickup.  Very exciting, especially since every time I refused to turn down a street posted \"No Trucks\" the TND 700 took almost 5 minutes to figure a re-route, and it happened multiple times on that short trip.I decided to give it another chance.  After my pickup on the north side of Cincinnati just off of I-75 I needed to head to Phoenix AZ via I-71.  Easy route is to just hop on I-75 and drive west and south to the intersection of I-71.  Indeed, that is what my cell phone advised.  The TND 700, however, wanted to route me over surface streets across the city and pick up I-75 on the other side of the city.  I turned it off and the next time I passed a truck stop of the same chain I purchased it at I returned it and got my money back.I then spent $30 on a cheap printer.  Now I take a minute to set up my route on Google and print it out.  Hasn\\'t gotten me lost yet over several cross country trips.'}\n",
            "Error Type: AuthenticationError, Message: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-****************************************************************************************************************************************************************************************************************************************0fd9. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[-------------------------------------------->     ] 18/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example fa39d4c9-596c-46ae-8d95-4bc36a81dc39 with inputs {'review': \"Summarize this customer review:\\nWell, what can I say.  I've had this unit in my truck for about four days now.  Prior to that I had a Garmin 755T non-truck GPS.  One of my favorite features in that unit was the ability to plan a route by determining mileage using the stop or via feature.  What I would do is using a map I would route myself several different ways forcing the unit by putting in stops or vias at different locations along the route, otherwise, like most GPS 's, it determines what it thinks is the best route.  I could add up to 10 Via's or stop points for each route and then based on mileage and other factors determine which is the best route to take.  Multiple stops and the ability to route was the most important reason for having the Garmin.  However it was not truck specific.  And considering I am now hauling strictly hazmat I wanted something that would take that into consideration.  After perusing various forums, review sites, and word-of-mouth my choices boiled down to the Garmin 465T or the RAND McNally Intelliroute TND 700.  Even though it was quite a bit more than the Garmin I chose the TND 700 for several reasons.  The main one being the extra screen size, and its ability to coordinate with the RAND McNally truck atlas and also its ease of updating.Now on to my first impression of the TND 700.  It seems to be an aesthetically pleasing and durably built unit.  The first thing I noticed was it's very slow to boot compared to my old Garmin.  Whether this is unique to the TND 700 or is common amongst all truck specific gps units I cannot tell, but it's really not that big of a deal.  The second thing I noticed was the overwhelming wealth of information put forth.  That might explain why the manual (available via the TND dock) is well over 100 pages long.....  There is somewhat of a learning curve with this unit.  The next thing I noticed was the complexity of entering routes.  As previously mentioned I like to force it into my preferred routing by the use of stops or vias.  That was a big no go with this unit.  While you can enter multiple stops or vias it is nowhere near as user-friendly as my old Garmin.  Furthermore there is no way you can determine total mileage on the route that you have chosen, as I could with the Garmin.  Totally flummoxed by what appeared to be an omission of one of the best routing tools a trucker could have I went online and verified through an expert source connected with RAND McNally that no, that feature was a couple updates down the line and was not available at this point.  Unbelievable.  Also forcing the unit to follow a specific route can be very challenging.  For a unit of this price, and feature laden, I find this totally unacceptable.  I am still mulling over selling this unit  and buying the Garmin 465T.  I really do like this GPS, the screen is magnificent, and the volume is awesome.Another thing I've noticed, which I do not think is unique to this unit, is some of the weird routing that it does.  I've never owned a truck specific GPS before but after playing with this one for a couple of days I get the impression that what RAND MacNally (and the others that use Navteq) has done is take a plain old car specific Navteq map and a road atlas with truck restrictions and made notifications on the map.  In most databases there is not a 100% thorough listing of every road in the country.  What I mean is that this unit will route you down roads you don't belong on.  Today while coming home it tried routing me on several  9 ton County roads.  What that means is that a truck is limited to 73280 unless the road is posted at 10 tons.  County roads do not have that restriction listed in the RAND McNally road atlas, so I believe that is why it is not listed.....  Also unacceptable in a unit of this price and sold as truck specific.  However I'd be willing to bet the other truck specific units are the same way as no one has ever done a truck specific version of NavTeq.Another bone I have to pick is the POI's. Not only the truck specific ones but the others all seem to be somewhat outdated.  I think the Garmin, at least the ones that I have used, are more current.  It would also be nice if I could add my own POI'sTo sum it up I will keep this unit a little longer to see if I can make it workable.  If not I will go back to Garmin.  I like the concept and I like the unit but at this point I'll have to say I am somewhat unimpressed.pros:Large screenterrific imagesoutstanding volumecons:inability to determine route mileage by multiple stops and viasa somewhat outdated POI information.Non-truck specific routings.Cost.\"}\n",
            "Error Type: AuthenticationError, Message: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-****************************************************************************************************************************************************************************************************************************************0fd9. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[----------------------------------------------->  ] 19/20"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.smith.evaluation.runner_utils:LLM failed for example 5dc83dd7-d15e-4187-8551-1ec579f77af2 with inputs {'review': 'Summarize this customer review:\\nThe cable is very wobbly and sometimes disconnects itself.The price is completely unfair and only works with the Nook HD and HD+'}\n",
            "Error Type: AuthenticationError, Message: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-****************************************************************************************************************************************************************************************************************************************0fd9. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[------------------------------------------------->] 20/20"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'project_name': 'OpenAI 2025-04-23 06:30:45',\n",
              " 'results': {'005ae3ad-ee35-489d-96be-e3b4a397e200': {'input': {'review': \"Summarize this customer review:\\nIt does 2A and charges a DEAD Nook in a few hours. It does so with a LOT of heat, compared to most wall worts. I have a dual charger where 1 port is 2.1A and the other is 1A for total output of 3.1A that doesn't run as hot as this. And i use that to power a raspberry pi to avoid needing a powered hubIt does the job adequately as it's designed to. Just hot. I would always unplug it if not using (even though it cools off) because of the amount of heat made. The nook hd+ runs hot too right where you hold it on the left side in portrait, but not so much when charging. I guess it's better to have it at the plug.\"},\n",
              "   'feedback': [EvaluationResult(key='embedding_cosine_distance', score=None, value=None, comment=\"Error evaluating run d0a0db17-54b1-402a-9bfb-a0657b7367bf: Could not parse LM prediction from run outputs {'generations': [], 'llm_output': None, 'run': None, 'type': 'LLMResult'}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None, extra=None)],\n",
              "   'execution_time': 0.349759,\n",
              "   'run_id': 'd0a0db17-54b1-402a-9bfb-a0657b7367bf',\n",
              "   'Error': openai.AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-****************************************************************************************************************************************************************************************************************************************0fd9. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\"),\n",
              "   'reference': {'summary': 'This is the oem charger you get with the nook hd+'}},\n",
              "  '00d85bc8-3237-4d06-8520-f60a4a2e1844': {'input': {'review': 'Summarize this customer review:\\nI am using this with a Nook HD+. It works as described. The HD picture on my Samsung 52&#34; TV is excellent.'},\n",
              "   'feedback': [EvaluationResult(key='embedding_cosine_distance', score=None, value=None, comment=\"Error evaluating run 9c835f0b-e729-4977-bec4-4c95af116fe6: Could not parse LM prediction from run outputs {'generations': [], 'llm_output': None, 'run': None, 'type': 'LLMResult'}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None, extra=None)],\n",
              "   'execution_time': 0.223702,\n",
              "   'run_id': '9c835f0b-e729-4977-bec4-4c95af116fe6',\n",
              "   'Error': openai.AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-****************************************************************************************************************************************************************************************************************************************0fd9. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\"),\n",
              "   'reference': {'summary': 'HDMI Nook adapter cable'}},\n",
              "  '143c6d2d-4962-437a-9300-103d56cff9e3': {'input': {'review': 'Summarize this customer review:\\nThis product really works great but I found the following items you need to keep in mind:- You must have your power adapter connected for it to work...it plugs in the the bottom. It appears it needs power from the nook power adapter to operate.- The plug fits in loosely and you cannot move the Nook around much without holding the adapter in place.- On initial plugin it seems you need to rock it around to get the connection but then it seems solid.- It works with a 25ft high quality HDMI cable so you can put the NOOK across the room with you. Not tested with cheap cables.Warning...I found that my LG SmartTV 3D from a few years back does not work with this adapter but it does not seem to work with many things...bad software. This adapter works fine with other HDMI devices I have used like monitors and I am sure other TVs.Gave it five stars because it really is nice to extend the screen and use your Nook as a streaming server to your TV. Nice they made such a device.'},\n",
              "   'feedback': [EvaluationResult(key='embedding_cosine_distance', score=None, value=None, comment=\"Error evaluating run a2d1bad8-9397-48d9-9939-03a9242e1f08: Could not parse LM prediction from run outputs {'generations': [], 'llm_output': None, 'run': None, 'type': 'LLMResult'}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None, extra=None)],\n",
              "   'execution_time': 0.187417,\n",
              "   'run_id': 'a2d1bad8-9397-48d9-9939-03a9242e1f08',\n",
              "   'Error': openai.AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-****************************************************************************************************************************************************************************************************************************************0fd9. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\"),\n",
              "   'reference': {'summary': 'This works great but read the details...'}},\n",
              "  '2db7ae44-b835-4aef-a31f-dca0613aef88': {'input': {'review': 'Summarize this customer review:\\nWorks well, a little pricey I think for a charging cable, but then again, not losing the original would be a lot cheaper than any replacement'},\n",
              "   'feedback': [EvaluationResult(key='embedding_cosine_distance', score=None, value=None, comment=\"Error evaluating run fd5d7350-b096-4952-b021-a0ed24826886: Could not parse LM prediction from run outputs {'generations': [], 'llm_output': None, 'run': None, 'type': 'LLMResult'}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None, extra=None)],\n",
              "   'execution_time': 0.241578,\n",
              "   'run_id': 'fd5d7350-b096-4952-b021-a0ed24826886',\n",
              "   'Error': openai.AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-****************************************************************************************************************************************************************************************************************************************0fd9. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\"),\n",
              "   'reference': {'summary': 'Good replacement'}},\n",
              "  '48e11ae3-3535-4246-8b25-61e3516e8ccc': {'input': {'review': 'Summarize this customer review:\\nThis adapter easily connects my Nook HD 7&#34; to my HDTV through the HDMI cable.  This is good for traveling because it makes any hotel TV a potential smart TV so long as there is an accessible HDMI port.  It is also good for sharing photos from FB on a bigger screen. A bit pricey, but a good accessory to have.  Be sure to note that this is ONLY for the Nook HD and HD+ series.  It will not work with a standard Nook.'},\n",
              "   'feedback': [EvaluationResult(key='embedding_cosine_distance', score=None, value=None, comment=\"Error evaluating run c521844e-1f54-4295-9417-2ef427dd0fd7: Could not parse LM prediction from run outputs {'generations': [], 'llm_output': None, 'run': None, 'type': 'LLMResult'}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None, extra=None)],\n",
              "   'execution_time': 0.243982,\n",
              "   'run_id': 'c521844e-1f54-4295-9417-2ef427dd0fd7',\n",
              "   'Error': openai.AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-****************************************************************************************************************************************************************************************************************************************0fd9. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\"),\n",
              "   'reference': {'summary': 'A nice easy to use accessory.'}},\n",
              "  '4a1b846d-d05f-4889-83a6-e3d990eb18e8': {'input': {'review': 'Summarize this customer review:\\nWe got this GPS for my husband who is an (OTR) over the road trucker.  Very Impressed with the shipping time, it arrived a few days earlier than expected...  within a week of use however it started freezing up... could of just been a glitch in that unit.  Worked great when it worked!  Will work great for the normal person as well but does have the \"trucker\" option. (the big truck routes - tells you when a scale is coming up ect...)  Love the bigger screen, the ease of use, the ease of putting addresses into memory.  Nothing really bad to say about the unit with the exception of it freezing which is probably one in a million and that\\'s just my luck.  I contacted the seller and within minutes of my email I received a email back with instructions for an exchange! VERY impressed all the way around!'},\n",
              "   'feedback': [EvaluationResult(key='embedding_cosine_distance', score=None, value=None, comment=\"Error evaluating run 9558d6fc-4f5a-4ae3-ad7e-06ce24c7b3db: Could not parse LM prediction from run outputs {'generations': [], 'llm_output': None, 'run': None, 'type': 'LLMResult'}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None, extra=None)],\n",
              "   'execution_time': 0.268703,\n",
              "   'run_id': '9558d6fc-4f5a-4ae3-ad7e-06ce24c7b3db',\n",
              "   'Error': openai.AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-****************************************************************************************************************************************************************************************************************************************0fd9. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\"),\n",
              "   'reference': {'summary': 'Gotta have GPS!'}},\n",
              "  '5dc83dd7-d15e-4187-8551-1ec579f77af2': {'input': {'review': 'Summarize this customer review:\\nThe cable is very wobbly and sometimes disconnects itself.The price is completely unfair and only works with the Nook HD and HD+'},\n",
              "   'feedback': [EvaluationResult(key='embedding_cosine_distance', score=None, value=None, comment=\"Error evaluating run 261291de-942b-4944-a182-8a21dbf43a14: Could not parse LM prediction from run outputs {'generations': [], 'llm_output': None, 'run': None, 'type': 'LLMResult'}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None, extra=None)],\n",
              "   'execution_time': 0.271935,\n",
              "   'run_id': '261291de-942b-4944-a182-8a21dbf43a14',\n",
              "   'Error': openai.AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-****************************************************************************************************************************************************************************************************************************************0fd9. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\"),\n",
              "   'reference': {'summary': 'Cheap proprietary scam'}},\n",
              "  '68821ee5-6a0b-4c5d-abfb-3457695bc923': {'input': {'review': 'Summarize this customer review:\\nThis item is just as was described in the original description, works without any issues to be seen. Good product'},\n",
              "   'feedback': [EvaluationResult(key='embedding_cosine_distance', score=None, value=None, comment=\"Error evaluating run 40f5f938-3558-4d8c-80cf-20a63952c996: Could not parse LM prediction from run outputs {'generations': [], 'llm_output': None, 'run': None, 'type': 'LLMResult'}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None, extra=None)],\n",
              "   'execution_time': 0.224051,\n",
              "   'run_id': '40f5f938-3558-4d8c-80cf-20a63952c996',\n",
              "   'Error': openai.AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-****************************************************************************************************************************************************************************************************************************************0fd9. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\"),\n",
              "   'reference': {'summary': 'As expected'}},\n",
              "  '8b3d1006-2a97-41ba-82c7-1407b108db00': {'input': {'review': 'Summarize this customer review:\\nNot going to write a long review, even thought this unit deserves one. I\\'ve driven well over 1-mil miles and done most of my own routing so I pretty know whats the fastest and shortest. Have been using a basic garmin for the past three years and with ANY Gps unit they\\'ll ALL get you in trouble if you let them. I was really excited about this unit, due to the size and the features. Allot of great grafics and on screen info thats usefull. But the most basic item that it was lacking was the gps tracking. I gave this unit allot of leadway on its mistakes due to the fact that it had allot of cool stuff that it did, but its ability to track you and route you was not even close to what the basic garmin could due. Its like the prossesor that they installed in the TND 700 was 10 years old. Example if I needed to make a simple route change I.E. in town down to the next street due to the fact that I couldn\\'t make the turn or the street was blocked off, it would take the TND 700 upwards of 45 seconds to a minute and a half to reroute me. Here I\\'m sitting at a stop light waiting for directions and waiting that long with cars on my backside didn\\'t make me happy. This is a problem that happened evertime you had to reroute, weather it was a simple street change or a major highway change. Also from the time you turned the unit on it would take twice as long to boot itself up. At least a dozen times with in a week it put me on the wrong roads and when I made a wrong turn it got it self lost....I.E. take left on xyz street, and it was some ones drive way. Or turn left in 800 yards and the turn was less than 10 feet away. You might think in a conjested city situation I might get a little mixed up, but this is out in the country. Twice it put me under 12\\'6\" bridges when I\\'m 13\\'6\". Of course I made sure all my truck setting where they were supposed to be. I also updated the OS version,via Rand McNally. All in all I expected alot out of this unit and got a unit that should of been field tested with some people that drive allot. It just had to many route mistakes. Going back to the basic garmin. This isn\\'t just my complaints, I have three friends that bought the same unit and have the same complaints. All of us returned the units.'},\n",
              "   'feedback': [EvaluationResult(key='embedding_cosine_distance', score=None, value=None, comment=\"Error evaluating run 43f37218-64b6-4e33-97b0-793d8d70d421: Could not parse LM prediction from run outputs {'generations': [], 'llm_output': None, 'run': None, 'type': 'LLMResult'}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None, extra=None)],\n",
              "   'execution_time': 0.531767,\n",
              "   'run_id': '43f37218-64b6-4e33-97b0-793d8d70d421',\n",
              "   'Error': openai.AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-****************************************************************************************************************************************************************************************************************************************0fd9. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\"),\n",
              "   'reference': {'summary': 'Great grafics, POOR GPS'}},\n",
              "  '91339c19-0cd8-418a-9129-d46bfdc6250e': {'input': {'review': \"Summarize this customer review:\\nI've had mine for a year and here's what we got. It tries to route be down non truck routes while telling me the truck route is illegal for me. This is such a bad problem that even Interstate 25 in Denver Colorado is listed (according to this GPS) as a non- truck route and will route you through the city instead. There are several drivers within our company who own one and more than half (of about 50) have crashed to an un-recoverable state. Our company representative said that Rand McNally informed them that the GPS was not designed to say on for a long period of time. Really? it's a truck driver GPS. We have one driver with a $2400 dollar ticket due to this GPS routing him down the wrong road. The companies response was to update the unit. I've had mine for a year, I never noticed one update that corrected functionality, they only seem to keep messing the tools. I want a GPS that routes, if I wanted tools I'd buy software for my computer.My suggestion is to by a nice Garmen. My one rated for cars actually routes me better than this one rated for trucks.Wayne\"},\n",
              "   'feedback': [EvaluationResult(key='embedding_cosine_distance', score=None, value=None, comment=\"Error evaluating run d9d06783-b4fe-4b9a-aa57-bdea957bd2fa: Could not parse LM prediction from run outputs {'generations': [], 'llm_output': None, 'run': None, 'type': 'LLMResult'}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None, extra=None)],\n",
              "   'execution_time': 0.190236,\n",
              "   'run_id': 'd9d06783-b4fe-4b9a-aa57-bdea957bd2fa',\n",
              "   'Error': openai.AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-****************************************************************************************************************************************************************************************************************************************0fd9. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\"),\n",
              "   'reference': {'summary': 'Major issues, only excuses for support'}},\n",
              "  'ab78b702-46a5-498f-9d58-e30f2aefdfe3': {'input': {'review': 'Summarize this customer review:\\nMy son crewed my HD charger cord so I needed another one, this is exactly like the one my son destroyed.'},\n",
              "   'feedback': [EvaluationResult(key='embedding_cosine_distance', score=None, value=None, comment=\"Error evaluating run 1984a0ea-7a09-4bc3-a9e4-b6bfa0ae260d: Could not parse LM prediction from run outputs {'generations': [], 'llm_output': None, 'run': None, 'type': 'LLMResult'}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None, extra=None)],\n",
              "   'execution_time': 0.24525,\n",
              "   'run_id': '1984a0ea-7a09-4bc3-a9e4-b6bfa0ae260d',\n",
              "   'Error': openai.AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-****************************************************************************************************************************************************************************************************************************************0fd9. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\"),\n",
              "   'reference': {'summary': 'Works Great'}},\n",
              "  'b2892798-7715-4148-a086-3661a96a4b3a': {'input': {'review': 'Summarize this customer review:\\nbought for a spare for my 9&#34; Nook HD and it fit perfectly.  Very satisfied with the price much less than on the BN site'},\n",
              "   'feedback': [EvaluationResult(key='embedding_cosine_distance', score=None, value=None, comment=\"Error evaluating run 27229c0a-b815-43fe-b96e-07f35fa58799: Could not parse LM prediction from run outputs {'generations': [], 'llm_output': None, 'run': None, 'type': 'LLMResult'}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None, extra=None)],\n",
              "   'execution_time': 0.189059,\n",
              "   'run_id': '27229c0a-b815-43fe-b96e-07f35fa58799',\n",
              "   'Error': openai.AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-****************************************************************************************************************************************************************************************************************************************0fd9. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\"),\n",
              "   'reference': {'summary': 'great fit'}},\n",
              "  'b3b81043-1f6d-4d26-802f-7759f5aff7c7': {'input': {'review': \"Summarize this customer review:\\nThis adaptor is real easy to setup and use right out of the box. I had not problem with it at all, it is well worth the purchase. I recommend this adaptor very much for viewing your Nook videos on your HDTV. I just disagree with other reviews on the length of the adaptor, I found it to be fairly adequate as to how and where it is connected to my TV. For me it was just right not too long or too short, I was able to place my Nook right below the connection on the TV stand, it did not fall or anything else, it is fine. Use your own judgement, I'm too busy watching my movies :)\"},\n",
              "   'feedback': [EvaluationResult(key='embedding_cosine_distance', score=None, value=None, comment=\"Error evaluating run 6646880a-28ee-417e-a7f6-78ee932b22a0: Could not parse LM prediction from run outputs {'generations': [], 'llm_output': None, 'run': None, 'type': 'LLMResult'}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None, extra=None)],\n",
              "   'execution_time': 0.195467,\n",
              "   'run_id': '6646880a-28ee-417e-a7f6-78ee932b22a0',\n",
              "   'Error': openai.AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-****************************************************************************************************************************************************************************************************************************************0fd9. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\"),\n",
              "   'reference': {'summary': 'A Perfdect Nook HD+ hook up'}},\n",
              "  'c456879e-10a9-4a46-a8da-5b54e12316dc': {'input': {'review': \"Summarize this customer review:\\nThis is a good beefy 2 amp charger, but it covers two outlets on a power strip. It's ok in a regular wall outlet. The best thing is it uses a standard USB connector so it can charge more than just a Nook (I have a Kindle Fire HD+).\"},\n",
              "   'feedback': [EvaluationResult(key='embedding_cosine_distance', score=None, value=None, comment=\"Error evaluating run 937834c4-251c-41e9-bc8a-f364ad4d390e: Could not parse LM prediction from run outputs {'generations': [], 'llm_output': None, 'run': None, 'type': 'LLMResult'}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None, extra=None)],\n",
              "   'execution_time': 0.194719,\n",
              "   'run_id': '937834c4-251c-41e9-bc8a-f364ad4d390e',\n",
              "   'Error': openai.AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-****************************************************************************************************************************************************************************************************************************************0fd9. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\"),\n",
              "   'reference': {'summary': 'It Works'}},\n",
              "  'da4f2c1b-22a6-457d-850e-11346f2b3fd4': {'input': {'review': \"Summarize this customer review:\\nI lost my B&N original cable.  I looked around for an new one.  I tried  a different, cheaper model but it didn't fit my device properly so back to the drawing board.  I ordered this one.  I am satisfied.  It works exactly as expected and fits perfectly.  I would recommend this product to anyone looking for a spare or in lieu of the original usb cable adapter.\"},\n",
              "   'feedback': [EvaluationResult(key='embedding_cosine_distance', score=None, value=None, comment=\"Error evaluating run 784d351f-c5c1-4462-9975-d78806b0ac45: Could not parse LM prediction from run outputs {'generations': [], 'llm_output': None, 'run': None, 'type': 'LLMResult'}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None, extra=None)],\n",
              "   'execution_time': 0.150725,\n",
              "   'run_id': '784d351f-c5c1-4462-9975-d78806b0ac45',\n",
              "   'Error': openai.AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-****************************************************************************************************************************************************************************************************************************************0fd9. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\"),\n",
              "   'reference': {'summary': 'Great replacement for original power cable'}},\n",
              "  'e696f1e6-5ca5-4c1a-abe6-4db7afdfef2d': {'input': {'review': 'Summarize this customer review:\\nThis is a great buy, compared to a $60 or more a retail store.'},\n",
              "   'feedback': [EvaluationResult(key='embedding_cosine_distance', score=None, value=None, comment=\"Error evaluating run 26b5d257-062d-4fcb-83b7-7919eaf8fb98: Could not parse LM prediction from run outputs {'generations': [], 'llm_output': None, 'run': None, 'type': 'LLMResult'}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None, extra=None)],\n",
              "   'execution_time': 0.126692,\n",
              "   'run_id': '26b5d257-062d-4fcb-83b7-7919eaf8fb98',\n",
              "   'Error': openai.AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-****************************************************************************************************************************************************************************************************************************************0fd9. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\"),\n",
              "   'reference': {'summary': 'Excelant mount for Tv. Would buy more if I needed them.'}},\n",
              "  'e715ce27-6ce3-48a8-9f34-bc38cd0131f3': {'input': {'review': 'Summarize this customer review:\\nI\\'m a professional OTR truck driver, and I bought a TND 700 at a truck stop hoping to make my life easier.  Rand McNally, are you listening?First thing I did after charging it was connect it to my laptop and install the software and then attempt to update it.  The software detected a problem with my update and wanted my home address so I could be sent a patch on an SD card.  Hello?  I don\\'t think I\\'m all that unusual; my home address is a PO box that a friend checks weekly and that I might get to check every six months or so.  I live in my truck and at truck stops.  If you need to make a patch available on an SD card then you should send the SD cards to the truck stops where the devices are sold.  I ran the update program multiple times until the program said that the TND 700 was completely updated.I programmed in the height (13\\'6\"), the length (53\\') and the weight (80,000#) of my rig and told it that I preferred highways.  I was parked at a truck stop in the Cincinnati OH area.  My next pickup was about 15 miles down the same freeway but on the other side of it a couple of blocks.  My cell phone GPS (Sprint) said to get on the freeway to get to my pickup.  The TND 700 routed me thru 23 miles of residential streets before finally getting me to my pickup.  Very exciting, especially since every time I refused to turn down a street posted \"No Trucks\" the TND 700 took almost 5 minutes to figure a re-route, and it happened multiple times on that short trip.I decided to give it another chance.  After my pickup on the north side of Cincinnati just off of I-75 I needed to head to Phoenix AZ via I-71.  Easy route is to just hop on I-75 and drive west and south to the intersection of I-71.  Indeed, that is what my cell phone advised.  The TND 700, however, wanted to route me over surface streets across the city and pick up I-75 on the other side of the city.  I turned it off and the next time I passed a truck stop of the same chain I purchased it at I returned it and got my money back.I then spent $30 on a cheap printer.  Now I take a minute to set up my route on Google and print it out.  Hasn\\'t gotten me lost yet over several cross country trips.'},\n",
              "   'feedback': [EvaluationResult(key='embedding_cosine_distance', score=None, value=None, comment=\"Error evaluating run 834197ed-4ee3-4128-8ee4-8b2c63aa3c30: Could not parse LM prediction from run outputs {'generations': [], 'llm_output': None, 'run': None, 'type': 'LLMResult'}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None, extra=None)],\n",
              "   'execution_time': 0.203287,\n",
              "   'run_id': '834197ed-4ee3-4128-8ee4-8b2c63aa3c30',\n",
              "   'Error': openai.AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-****************************************************************************************************************************************************************************************************************************************0fd9. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\"),\n",
              "   'reference': {'summary': 'Very Disappointed'}},\n",
              "  'f4b60be0-a299-429d-9453-a5fa261f1793': {'input': {'review': 'Summarize this customer review:\\nThis mount is just what I needed.  It is strong and sturdy.  It folds almost flat to enable the television to sit square and flat against the wall if desired and extends and rotates for angle turns.  A perfect fit as long as you match the correct visa pattern for your television.'},\n",
              "   'feedback': [EvaluationResult(key='embedding_cosine_distance', score=None, value=None, comment=\"Error evaluating run d83fb061-bd47-42a3-9e2e-f6e05aa514f2: Could not parse LM prediction from run outputs {'generations': [], 'llm_output': None, 'run': None, 'type': 'LLMResult'}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None, extra=None)],\n",
              "   'execution_time': 0.114118,\n",
              "   'run_id': 'd83fb061-bd47-42a3-9e2e-f6e05aa514f2',\n",
              "   'Error': openai.AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-****************************************************************************************************************************************************************************************************************************************0fd9. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\"),\n",
              "   'reference': {'summary': 'Perfect'}},\n",
              "  'f5dde7d5-9548-44e8-90a1-2d3d97ae50aa': {'input': {'review': \"Summarize this customer review:\\nGo to Target or Barnes and Noble instead, and pay $25 (which is still a huge markup, considering they make the thing for 50 cents.) This is the worst option if you need one of these. It's price gouging, pure and simple.\"},\n",
              "   'feedback': [EvaluationResult(key='embedding_cosine_distance', score=None, value=None, comment=\"Error evaluating run 566f38fd-2630-454e-bfdb-ee68f2a4590e: Could not parse LM prediction from run outputs {'generations': [], 'llm_output': None, 'run': None, 'type': 'LLMResult'}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None, extra=None)],\n",
              "   'execution_time': 0.146396,\n",
              "   'run_id': '566f38fd-2630-454e-bfdb-ee68f2a4590e',\n",
              "   'Error': openai.AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-****************************************************************************************************************************************************************************************************************************************0fd9. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\"),\n",
              "   'reference': {'summary': '$45 for a power cord? Good luck with that.'}},\n",
              "  'fa39d4c9-596c-46ae-8d95-4bc36a81dc39': {'input': {'review': \"Summarize this customer review:\\nWell, what can I say.  I've had this unit in my truck for about four days now.  Prior to that I had a Garmin 755T non-truck GPS.  One of my favorite features in that unit was the ability to plan a route by determining mileage using the stop or via feature.  What I would do is using a map I would route myself several different ways forcing the unit by putting in stops or vias at different locations along the route, otherwise, like most GPS 's, it determines what it thinks is the best route.  I could add up to 10 Via's or stop points for each route and then based on mileage and other factors determine which is the best route to take.  Multiple stops and the ability to route was the most important reason for having the Garmin.  However it was not truck specific.  And considering I am now hauling strictly hazmat I wanted something that would take that into consideration.  After perusing various forums, review sites, and word-of-mouth my choices boiled down to the Garmin 465T or the RAND McNally Intelliroute TND 700.  Even though it was quite a bit more than the Garmin I chose the TND 700 for several reasons.  The main one being the extra screen size, and its ability to coordinate with the RAND McNally truck atlas and also its ease of updating.Now on to my first impression of the TND 700.  It seems to be an aesthetically pleasing and durably built unit.  The first thing I noticed was it's very slow to boot compared to my old Garmin.  Whether this is unique to the TND 700 or is common amongst all truck specific gps units I cannot tell, but it's really not that big of a deal.  The second thing I noticed was the overwhelming wealth of information put forth.  That might explain why the manual (available via the TND dock) is well over 100 pages long.....  There is somewhat of a learning curve with this unit.  The next thing I noticed was the complexity of entering routes.  As previously mentioned I like to force it into my preferred routing by the use of stops or vias.  That was a big no go with this unit.  While you can enter multiple stops or vias it is nowhere near as user-friendly as my old Garmin.  Furthermore there is no way you can determine total mileage on the route that you have chosen, as I could with the Garmin.  Totally flummoxed by what appeared to be an omission of one of the best routing tools a trucker could have I went online and verified through an expert source connected with RAND McNally that no, that feature was a couple updates down the line and was not available at this point.  Unbelievable.  Also forcing the unit to follow a specific route can be very challenging.  For a unit of this price, and feature laden, I find this totally unacceptable.  I am still mulling over selling this unit  and buying the Garmin 465T.  I really do like this GPS, the screen is magnificent, and the volume is awesome.Another thing I've noticed, which I do not think is unique to this unit, is some of the weird routing that it does.  I've never owned a truck specific GPS before but after playing with this one for a couple of days I get the impression that what RAND MacNally (and the others that use Navteq) has done is take a plain old car specific Navteq map and a road atlas with truck restrictions and made notifications on the map.  In most databases there is not a 100% thorough listing of every road in the country.  What I mean is that this unit will route you down roads you don't belong on.  Today while coming home it tried routing me on several  9 ton County roads.  What that means is that a truck is limited to 73280 unless the road is posted at 10 tons.  County roads do not have that restriction listed in the RAND McNally road atlas, so I believe that is why it is not listed.....  Also unacceptable in a unit of this price and sold as truck specific.  However I'd be willing to bet the other truck specific units are the same way as no one has ever done a truck specific version of NavTeq.Another bone I have to pick is the POI's. Not only the truck specific ones but the others all seem to be somewhat outdated.  I think the Garmin, at least the ones that I have used, are more current.  It would also be nice if I could add my own POI'sTo sum it up I will keep this unit a little longer to see if I can make it workable.  If not I will go back to Garmin.  I like the concept and I like the unit but at this point I'll have to say I am somewhat unimpressed.pros:Large screenterrific imagesoutstanding volumecons:inability to determine route mileage by multiple stops and viasa somewhat outdated POI information.Non-truck specific routings.Cost.\"},\n",
              "   'feedback': [EvaluationResult(key='embedding_cosine_distance', score=None, value=None, comment=\"Error evaluating run 6ceca67d-6cdb-43e4-9084-856ccb158c66: Could not parse LM prediction from run outputs {'generations': [], 'llm_output': None, 'run': None, 'type': 'LLMResult'}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None, extra=None)],\n",
              "   'execution_time': 0.186885,\n",
              "   'run_id': '6ceca67d-6cdb-43e4-9084-856ccb158c66',\n",
              "   'Error': openai.AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-****************************************************************************************************************************************************************************************************************************************0fd9. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\"),\n",
              "   'reference': {'summary': '1st impression'}}},\n",
              " 'aggregate_metrics': None}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e6899eb4c04d40b79c8e4d0ac08082d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_97871f0d4c6044e982804ee2c5db7101",
              "IPY_MODEL_7dd73b93420546cca6726758f78c5bde",
              "IPY_MODEL_e3b826ca45234699859d8d6c1298f670"
            ],
            "layout": "IPY_MODEL_8a635343dde14ce8bb10c7dd7d01dc55"
          }
        },
        "97871f0d4c6044e982804ee2c5db7101": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b59393451c641c9807007a096fa956e",
            "placeholder": "​",
            "style": "IPY_MODEL_016d45bf3430435faa794b2fc0069ebe",
            "value": "Generating train split: "
          }
        },
        "7dd73b93420546cca6726758f78c5bde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4dcf77794db4d60b1850a63d3965ca9",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06cd07a39079433aa0250e3feda51524",
            "value": 1
          }
        },
        "e3b826ca45234699859d8d6c1298f670": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ca5bdd5ef8c4ae1bc54a1d171c6c273",
            "placeholder": "​",
            "style": "IPY_MODEL_cb8c9f1a17db40d898ae910466ba886c",
            "value": " 1689188/0 [00:10&lt;00:00, 137162.88 examples/s]"
          }
        },
        "8a635343dde14ce8bb10c7dd7d01dc55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b59393451c641c9807007a096fa956e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "016d45bf3430435faa794b2fc0069ebe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4dcf77794db4d60b1850a63d3965ca9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "06cd07a39079433aa0250e3feda51524": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ca5bdd5ef8c4ae1bc54a1d171c6c273": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb8c9f1a17db40d898ae910466ba886c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67b58846594d40a9b6d9e854cc5ad702": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cbc74bd17d29446884ea5894e3842676",
              "IPY_MODEL_503c67016707445dbb0650053c722d92",
              "IPY_MODEL_10658ec45c3049b98bfbb35c216384ae"
            ],
            "layout": "IPY_MODEL_55250c78778b431f84d7deb0661b5219"
          }
        },
        "cbc74bd17d29446884ea5894e3842676": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04a98f1be8be45b891090569ebf79f59",
            "placeholder": "​",
            "style": "IPY_MODEL_c5ab879808ff431d90ca1a0e28728daa",
            "value": "Map: 100%"
          }
        },
        "503c67016707445dbb0650053c722d92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf6f1f4ce0d44a5ba57b511f95953161",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a46b980a03cb4a5eb8af0de9e32c21a2",
            "value": 20
          }
        },
        "10658ec45c3049b98bfbb35c216384ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99731e13188049b6a16820370ff8bfe1",
            "placeholder": "​",
            "style": "IPY_MODEL_6f8cf7c64a3349a298f19529736dff85",
            "value": " 20/20 [00:00&lt;00:00, 1206.77 examples/s]"
          }
        },
        "55250c78778b431f84d7deb0661b5219": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04a98f1be8be45b891090569ebf79f59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5ab879808ff431d90ca1a0e28728daa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf6f1f4ce0d44a5ba57b511f95953161": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a46b980a03cb4a5eb8af0de9e32c21a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "99731e13188049b6a16820370ff8bfe1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f8cf7c64a3349a298f19529736dff85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9d3f0c835874b2c9f6a17422e6d0f78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6688d21811a040ed814adc833e81cbd3",
              "IPY_MODEL_fa3c4b03b7c14793b8b544a6e14a9f89",
              "IPY_MODEL_e7914bcf73f24768ab2a739c6d1b70cb"
            ],
            "layout": "IPY_MODEL_72145e841ea1485ba1bb3ee4e4e8aa6e"
          }
        },
        "6688d21811a040ed814adc833e81cbd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7b2af2fccc04ebd842b264bea776282",
            "placeholder": "​",
            "style": "IPY_MODEL_5f2c5b6112004f1784ff7fb0e252f249",
            "value": "Creating CSV from Arrow format: 100%"
          }
        },
        "fa3c4b03b7c14793b8b544a6e14a9f89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c034804727d247449b518d17675f45b7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7a71a3380d14c4e8e376017ac42956c",
            "value": 1
          }
        },
        "e7914bcf73f24768ab2a739c6d1b70cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98cd6bfd3e6c40cb9614f441a24eb1b2",
            "placeholder": "​",
            "style": "IPY_MODEL_6d5f98e6f0b5482fb261ddea40b0af56",
            "value": " 1/1 [00:00&lt;00:00, 63.25ba/s]"
          }
        },
        "72145e841ea1485ba1bb3ee4e4e8aa6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7b2af2fccc04ebd842b264bea776282": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f2c5b6112004f1784ff7fb0e252f249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c034804727d247449b518d17675f45b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7a71a3380d14c4e8e376017ac42956c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "98cd6bfd3e6c40cb9614f441a24eb1b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d5f98e6f0b5482fb261ddea40b0af56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}